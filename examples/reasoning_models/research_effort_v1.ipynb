{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Cookbook: Working with O‑Series Models (o3‑mini)\n",
    "========================================================\n",
    "\n",
    "This cookbook demonstrates how to:\n",
    "• Set up and call an O‑series model with different reasoning efforts.\n",
    "• Evaluate model responses using sample questions and a public dataset.\n",
    "• Analyze token usage (total and reasoning tokens), response times, and accuracy.\n",
    "• Understand best practices for prompting, reasoning effort levels, and response logging.\n",
    "\n",
    "Before running this code, ensure you have installed the required libraries:\n",
    "   -  pip install openai --upgrade\n",
    "   -  pip install pandas\n",
    "   -  pip install datasets\n",
    "\n",
    "You should also have your OpenAI API key set in the environment variable:\n",
    "    OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "MODEL_NAME = \"o3-mini\"  # Choose your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample questions and expected answers\n",
    "sample_questions = [\n",
    "    {\n",
    "        \"question\": \"A bat and a ball cost $1.10 in total. The bat costs $1.00 more than the ball. How much does the ball cost?\",\n",
    "        \"answer\": \"0.05\"  # Expected correct answer in dollars\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"If 5 machines take 5 minutes to make 5 widgets, how long would 100 machines take to make 100 widgets?\",\n",
    "        \"answer\": \"5 minutes\"  # Expected correct answer\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"The $n=2$ level of the hydrogen atom is fourfold degenerate (the $2s$ and $2p$ orbitals). Consider a hydrogen atom placed in a constant electric field $E$ directed along the $z$-axis (Stark effect). Using first-order degenerate perturbation theory, determine the energy shifts of the $n=2$ levels to first order in $E$. Identify which states are mixed by the perturbation and find the new eigenstates and their energies. (Neglect fine structure and spin.)\",\n",
    "        \"answer\": \"TBD\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Consider $N$ non-interacting spin-$\\frac{1}{2}$ particles (such as paramagnetic atoms with a single unpaired electron) in a uniform magnetic field $B$ at temperature $T$. Each spin can be either aligned with the field (down state energy $+\\mu B$) or against the field (up state energy $-\\mu B$), where $\\mu$ is the magnetic moment (assume $\\mu B \\ll$ any saturation limits so no other levels). (a) Derive an expression for the total magnetization $M$ of the system as a function of $B$ and $T$. (b) Discuss the behavior of $M$ in the limits of very low temperature and very high temperature, and verify that it is consistent with physical expectations (Curie's law at high $T$, saturation at low $T$).\",\n",
    "        \"answer\": \"TBD\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_with_reasoning(question: str, reasoning_level: str = \"low\"):\n",
    "    \"\"\"\n",
    "    Send a question to the OpenAI model with a given reasoning effort level.\n",
    "    \n",
    "    Parameters:\n",
    "        question (str): The input prompt.\n",
    "        reasoning_level (str): The reasoning effort level (\"low\", \"medium\", or \"high\").\n",
    "    \n",
    "    Returns:\n",
    "        answer (str): The model's answer.\n",
    "        total_tokens (int): Total token usage.\n",
    "        reasoning_tokens (Optional[int]): Number of tokens used for reasoning (if available).\n",
    "        response_time (float): The time (in seconds) taken for the API call.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        reasoning_effort=reasoning_level,\n",
    "        messages=[{\"role\": \"user\", \"content\": question}]\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    answer = response.choices[0].message.content.strip()\n",
    "    usage = response.usage\n",
    "    total_tokens = usage.total_tokens\n",
    "    reasoning_tokens = None\n",
    "    if usage.completion_tokens_details.reasoning_tokens is not None:\n",
    "        reasoning_tokens = usage.completion_tokens_details.reasoning_tokens\n",
    "    return answer, total_tokens, reasoning_tokens, (end_time - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_questions(questions, reasoning_levels=[\"low\", \"medium\", \"high\"], check_correct=False):\n",
    "    \"\"\"\n",
    "    Evaluate a list of questions using multiple reasoning effort levels.\n",
    "    \n",
    "    Parameters:\n",
    "        questions (list of dict): Each dict should have keys 'question' and optionally 'answer'.\n",
    "        reasoning_levels (list): List of reasoning levels to test.\n",
    "        check_correct (bool): If True, a simple heuristic checks if the model's answer\n",
    "                              matches the expected answer.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Contains results for each question and reasoning level.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for item in questions:\n",
    "        question_text = item[\"question\"]\n",
    "        expected = item.get(\"answer\", None)\n",
    "        for level in reasoning_levels:\n",
    "            try:\n",
    "                answer, total_tokens, reasoning_tokens, response_time = ask_with_reasoning(question_text, reasoning_level=level)\n",
    "                correct = None\n",
    "                if check_correct and expected is not None:\n",
    "                    # Normalize for a simple substring match\n",
    "                    ans_norm = answer.lower().strip()\n",
    "                    exp_norm = str(expected).lower().strip()\n",
    "                    correct = (exp_norm in ans_norm or ans_norm in exp_norm)\n",
    "                results.append({\n",
    "                    \"question\": question_text,\n",
    "                    \"expected\": expected,\n",
    "                    \"level\": level,\n",
    "                    \"model_answer\": answer,\n",
    "                    \"correct\": correct,\n",
    "                    \"total_tokens\": total_tokens,\n",
    "                    \"reasoning_tokens\": reasoning_tokens,\n",
    "                    \"response_time\": response_time\n",
    "                })\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing question '{question_text}' at level '{level}': {e}\")\n",
    "                results.append({\n",
    "                    \"question\": question_text,\n",
    "                    \"expected\": expected,\n",
    "                    \"level\": level,\n",
    "                    \"model_answer\": None,\n",
    "                    \"correct\": False,\n",
    "                    \"total_tokens\": None,\n",
    "                    \"reasoning_tokens\": None,\n",
    "                    \"response_time\": None\n",
    "                })\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating sample questions with different reasoning efforts...\n",
      "                                            question   expected   level  \\\n",
      "0  A bat and a ball cost $1.10 in total. The bat ...       0.05     low   \n",
      "1  A bat and a ball cost $1.10 in total. The bat ...       0.05  medium   \n",
      "2  A bat and a ball cost $1.10 in total. The bat ...       0.05    high   \n",
      "3  If 5 machines take 5 minutes to make 5 widgets...  5 minutes     low   \n",
      "4  If 5 machines take 5 minutes to make 5 widgets...  5 minutes  medium   \n",
      "\n",
      "                                        model_answer  correct  total_tokens  \\\n",
      "0  Let the cost of the ball be x dollars. Since t...     True           179   \n",
      "1  Let the cost of the ball be x dollars. Then th...     True           427   \n",
      "2  Let's denote the cost of the ball as x dollars...     True           622   \n",
      "3  The key is to understand the production rate o...     True           190   \n",
      "4  If 5 machines take 5 minutes to produce 5 widg...     True           290   \n",
      "\n",
      "   reasoning_tokens  response_time  \n",
      "0                 0       3.968576  \n",
      "1               256       2.519180  \n",
      "2               448      10.968315  \n",
      "3                64       1.507613  \n",
      "4               192       2.657307  \n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating sample questions with different reasoning efforts...\")\n",
    "df_sample = evaluate_questions(sample_questions, check_correct=True)\n",
    "print(df_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>expected</th>\n",
       "      <th>level</th>\n",
       "      <th>model_answer</th>\n",
       "      <th>correct</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>reasoning_tokens</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A bat and a ball cost $1.10 in total. The bat ...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>low</td>\n",
       "      <td>Let the cost of the ball be x dollars. Since t...</td>\n",
       "      <td>True</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>3.968576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A bat and a ball cost $1.10 in total. The bat ...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>medium</td>\n",
       "      <td>Let the cost of the ball be x dollars. Then th...</td>\n",
       "      <td>True</td>\n",
       "      <td>427</td>\n",
       "      <td>256</td>\n",
       "      <td>2.519180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A bat and a ball cost $1.10 in total. The bat ...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>high</td>\n",
       "      <td>Let's denote the cost of the ball as x dollars...</td>\n",
       "      <td>True</td>\n",
       "      <td>622</td>\n",
       "      <td>448</td>\n",
       "      <td>10.968315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If 5 machines take 5 minutes to make 5 widgets...</td>\n",
       "      <td>5 minutes</td>\n",
       "      <td>low</td>\n",
       "      <td>The key is to understand the production rate o...</td>\n",
       "      <td>True</td>\n",
       "      <td>190</td>\n",
       "      <td>64</td>\n",
       "      <td>1.507613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If 5 machines take 5 minutes to make 5 widgets...</td>\n",
       "      <td>5 minutes</td>\n",
       "      <td>medium</td>\n",
       "      <td>If 5 machines take 5 minutes to produce 5 widg...</td>\n",
       "      <td>True</td>\n",
       "      <td>290</td>\n",
       "      <td>192</td>\n",
       "      <td>2.657307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>If 5 machines take 5 minutes to make 5 widgets...</td>\n",
       "      <td>5 minutes</td>\n",
       "      <td>high</td>\n",
       "      <td>If 5 machines take 5 minutes to make 5 widgets...</td>\n",
       "      <td>True</td>\n",
       "      <td>683</td>\n",
       "      <td>576</td>\n",
       "      <td>4.773492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The $n=2$ level of the hydrogen atom is fourfo...</td>\n",
       "      <td>TBD</td>\n",
       "      <td>low</td>\n",
       "      <td>We wish to find the first‐order energy shifts ...</td>\n",
       "      <td>False</td>\n",
       "      <td>2463</td>\n",
       "      <td>576</td>\n",
       "      <td>12.124599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The $n=2$ level of the hydrogen atom is fourfo...</td>\n",
       "      <td>TBD</td>\n",
       "      <td>medium</td>\n",
       "      <td>We start by noting that the four n = 2 states ...</td>\n",
       "      <td>False</td>\n",
       "      <td>3018</td>\n",
       "      <td>1536</td>\n",
       "      <td>17.955862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The $n=2$ level of the hydrogen atom is fourfo...</td>\n",
       "      <td>TBD</td>\n",
       "      <td>high</td>\n",
       "      <td>We wish to find the first‐order energy shifts ...</td>\n",
       "      <td>False</td>\n",
       "      <td>8662</td>\n",
       "      <td>6976</td>\n",
       "      <td>49.791513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Consider $N$ non-interacting spin-$\frac{1}{2}$...</td>\n",
       "      <td>TBD</td>\n",
       "      <td>low</td>\n",
       "      <td>We start by noting that each spin-½ particle i...</td>\n",
       "      <td>False</td>\n",
       "      <td>1169</td>\n",
       "      <td>128</td>\n",
       "      <td>7.308833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Consider $N$ non-interacting spin-$\frac{1}{2}$...</td>\n",
       "      <td>TBD</td>\n",
       "      <td>medium</td>\n",
       "      <td>We begin by considering a single spin‐½ partic...</td>\n",
       "      <td>False</td>\n",
       "      <td>2177</td>\n",
       "      <td>1088</td>\n",
       "      <td>11.524883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Consider $N$ non-interacting spin-$\frac{1}{2}$...</td>\n",
       "      <td>TBD</td>\n",
       "      <td>high</td>\n",
       "      <td>We start by considering that each spin‐½ parti...</td>\n",
       "      <td>False</td>\n",
       "      <td>2528</td>\n",
       "      <td>1408</td>\n",
       "      <td>19.378853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question   expected   level  \\\n",
       "0   A bat and a ball cost $1.10 in total. The bat ...       0.05     low   \n",
       "1   A bat and a ball cost $1.10 in total. The bat ...       0.05  medium   \n",
       "2   A bat and a ball cost $1.10 in total. The bat ...       0.05    high   \n",
       "3   If 5 machines take 5 minutes to make 5 widgets...  5 minutes     low   \n",
       "4   If 5 machines take 5 minutes to make 5 widgets...  5 minutes  medium   \n",
       "5   If 5 machines take 5 minutes to make 5 widgets...  5 minutes    high   \n",
       "6   The $n=2$ level of the hydrogen atom is fourfo...        TBD     low   \n",
       "7   The $n=2$ level of the hydrogen atom is fourfo...        TBD  medium   \n",
       "8   The $n=2$ level of the hydrogen atom is fourfo...        TBD    high   \n",
       "9   Consider $N$ non-interacting spin-$\n",
       "rac{1}{2}$...        TBD     low   \n",
       "10  Consider $N$ non-interacting spin-$\n",
       "rac{1}{2}$...        TBD  medium   \n",
       "11  Consider $N$ non-interacting spin-$\n",
       "rac{1}{2}$...        TBD    high   \n",
       "\n",
       "                                         model_answer  correct  total_tokens  \\\n",
       "0   Let the cost of the ball be x dollars. Since t...     True           179   \n",
       "1   Let the cost of the ball be x dollars. Then th...     True           427   \n",
       "2   Let's denote the cost of the ball as x dollars...     True           622   \n",
       "3   The key is to understand the production rate o...     True           190   \n",
       "4   If 5 machines take 5 minutes to produce 5 widg...     True           290   \n",
       "5   If 5 machines take 5 minutes to make 5 widgets...     True           683   \n",
       "6   We wish to find the first‐order energy shifts ...    False          2463   \n",
       "7   We start by noting that the four n = 2 states ...    False          3018   \n",
       "8   We wish to find the first‐order energy shifts ...    False          8662   \n",
       "9   We start by noting that each spin-½ particle i...    False          1169   \n",
       "10  We begin by considering a single spin‐½ partic...    False          2177   \n",
       "11  We start by considering that each spin‐½ parti...    False          2528   \n",
       "\n",
       "    reasoning_tokens  response_time  \n",
       "0                  0       3.968576  \n",
       "1                256       2.519180  \n",
       "2                448      10.968315  \n",
       "3                 64       1.507613  \n",
       "4                192       2.657307  \n",
       "5                576       4.773492  \n",
       "6                576      12.124599  \n",
       "7               1536      17.955862  \n",
       "8               6976      49.791513  \n",
       "9                128       7.308833  \n",
       "10              1088      11.524883  \n",
       "11              1408      19.378853  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary for sample questions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>avg_total_tokens</th>\n",
       "      <th>avg_reasoning_tokens</th>\n",
       "      <th>avg_response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high</td>\n",
       "      <td>3123.75</td>\n",
       "      <td>2352.0</td>\n",
       "      <td>21.228043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>low</td>\n",
       "      <td>1000.25</td>\n",
       "      <td>192.0</td>\n",
       "      <td>6.227405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medium</td>\n",
       "      <td>1478.00</td>\n",
       "      <td>768.0</td>\n",
       "      <td>8.664308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    level  avg_total_tokens  avg_reasoning_tokens  avg_response_time\n",
       "0    high           3123.75                2352.0          21.228043\n",
       "1     low           1000.25                 192.0           6.227405\n",
       "2  medium           1478.00                 768.0           8.664308"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate and summarize token usage and response time by reasoning level\n",
    " \n",
    "summary = df_sample.groupby(\"level\").agg({\n",
    "\"total_tokens\": \"mean\",\n",
    "\"reasoning_tokens\": \"mean\",\n",
    "\"response_time\": \"mean\"}).reset_index()\n",
    "\n",
    "summary.rename(columns={\n",
    "    \"total_tokens\": \"avg_total_tokens\", \n",
    "    \"reasoning_tokens\": \"avg_reasoning_tokens\",\n",
    "    \"response_time\": \"avg_response_time\"\n",
    "}, inplace=True)\n",
    "\n",
    "print(\"\\nSummary for sample questions:\")\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -------------------------------\n",
    "#### Part 2: Evaluate Dataset Questions (ARC-Challenge)\n",
    "#### -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /Users/shikhar/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/shikhar/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-19.0.0-cp311-cp311-macosx_12_0_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /Users/shikhar/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/shikhar/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/shikhar/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.5.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /Users/shikhar/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /Users/shikhar/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from datasets) (0.26.2)\n",
      "Requirement already satisfied: packaging in /Users/shikhar/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/shikhar/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/shikhar/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/shikhar/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/shikhar/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/shikhar/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/shikhar/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/shikhar/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/shikhar/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/shikhar/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/shikhar/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shikhar/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/shikhar/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shikhar/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/shikhar/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/shikhar/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/shikhar/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/shikhar/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-19.0.0-cp311-cp311-macosx_12_0_x86_64.whl (32.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.1/32.1 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-macosx_10_9_x86_64.whl (31 kB)\n",
      "Installing collected packages: xxhash, pyarrow, fsspec, dill, multiprocess, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "Successfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 pyarrow-19.0.0 xxhash-3.5.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0228f92bc884abbb94d6a4b7e8c6785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/9.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e59a1aeda9e34b9980bd3d29d33c3733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/190k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd9e747d1984254ae0802c1842dc030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/204k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889c4a8796cd4e919a9caaf0eaf76a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/55.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1129ecf414449e94ca0f1ccdf637b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db5fd142ef9487297e6321904baba71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1172 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c6edccedf34529b8944c2e0698fb44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/299 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"allenai/ai2_arc\", \"ARC-Challenge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'question', 'choices', 'answerKey'],\n",
       "        num_rows: 1119\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'question', 'choices', 'answerKey'],\n",
       "        num_rows: 1172\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'question', 'choices', 'answerKey'],\n",
       "        num_rows: 299\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>choices</th>\n",
       "      <th>answerKey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mercury_SC_415702</td>\n",
       "      <td>George wants to warm his hands quickly by rubb...</td>\n",
       "      <td>{'text': ['dry palms', 'wet palms', 'palms cov...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MCAS_2009_5_6516</td>\n",
       "      <td>Which of the following statements best explain...</td>\n",
       "      <td>{'text': ['The refrigerator door is smooth.', ...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mercury_7233695</td>\n",
       "      <td>A fold observed in layers of sedimentary rock ...</td>\n",
       "      <td>{'text': ['cooling of flowing magma.', 'conver...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mercury_7041615</td>\n",
       "      <td>Which of these do scientists offer as the most...</td>\n",
       "      <td>{'text': ['worldwide disease', 'global mountai...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mercury_7041860</td>\n",
       "      <td>A boat is acted on by a river current flowing ...</td>\n",
       "      <td>{'text': ['west', 'east', 'north', 'south'], '...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                           question  \\\n",
       "0  Mercury_SC_415702  George wants to warm his hands quickly by rubb...   \n",
       "1   MCAS_2009_5_6516  Which of the following statements best explain...   \n",
       "2    Mercury_7233695  A fold observed in layers of sedimentary rock ...   \n",
       "3    Mercury_7041615  Which of these do scientists offer as the most...   \n",
       "4    Mercury_7041860  A boat is acted on by a river current flowing ...   \n",
       "\n",
       "                                             choices answerKey  \n",
       "0  {'text': ['dry palms', 'wet palms', 'palms cov...         A  \n",
       "1  {'text': ['The refrigerator door is smooth.', ...         B  \n",
       "2  {'text': ['cooling of flowing magma.', 'conver...         B  \n",
       "3  {'text': ['worldwide disease', 'global mountai...         D  \n",
       "4  {'text': ['west', 'east', 'north', 'south'], '...         B  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(ds[\"train\"])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>level</th>\n",
       "      <th>model_answer</th>\n",
       "      <th>correct</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>reasoning_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>George wants to warm his hands quickly by rubb...</td>\n",
       "      <td>low</td>\n",
       "      <td>Rubbing dry skin creates a higher coefficient ...</td>\n",
       "      <td>True</td>\n",
       "      <td>242</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>George wants to warm his hands quickly by rubb...</td>\n",
       "      <td>medium</td>\n",
       "      <td>The answer is A: dry palms.\\n\\nExplanation: Wh...</td>\n",
       "      <td>True</td>\n",
       "      <td>473</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>George wants to warm his hands quickly by rubb...</td>\n",
       "      <td>high</td>\n",
       "      <td>Rubbing two surfaces together produces heat du...</td>\n",
       "      <td>True</td>\n",
       "      <td>936</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which of the following statements best explain...</td>\n",
       "      <td>low</td>\n",
       "      <td>The best explanation is that the refrigerator ...</td>\n",
       "      <td>True</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which of the following statements best explain...</td>\n",
       "      <td>medium</td>\n",
       "      <td>The best explanation is: B. The refrigerator d...</td>\n",
       "      <td>True</td>\n",
       "      <td>205</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question   level  \\\n",
       "0  George wants to warm his hands quickly by rubb...     low   \n",
       "1  George wants to warm his hands quickly by rubb...  medium   \n",
       "2  George wants to warm his hands quickly by rubb...    high   \n",
       "3  Which of the following statements best explain...     low   \n",
       "4  Which of the following statements best explain...  medium   \n",
       "\n",
       "                                        model_answer  correct  total_tokens  \\\n",
       "0  Rubbing dry skin creates a higher coefficient ...     True           242   \n",
       "1  The answer is A: dry palms.\\n\\nExplanation: Wh...     True           473   \n",
       "2  Rubbing two surfaces together produces heat du...     True           936   \n",
       "3  The best explanation is that the refrigerator ...     True           132   \n",
       "4  The best explanation is: B. The refrigerator d...     True           205   \n",
       "\n",
       "   reasoning_tokens  \n",
       "0                64  \n",
       "1               320  \n",
       "2               768  \n",
       "3                 0  \n",
       "4                64  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []  # to accumulate results for each question and level\n",
    "\n",
    "for item in range(2):\n",
    "    q_text = str(df.iloc[item].question) + \"\\n\" + \"choices: \" + str(df.iloc[item].choices)\n",
    "    #q_choices = df.iloc[item][\"question_choices\"]\n",
    "    expected = df.iloc[item].answerKey\n",
    "    for level in [\"low\", \"medium\", \"high\"]:\n",
    "        try:\n",
    "            answer, total_tokens, reasoning_tokens = ask_with_reasoning(q_text, reasoning_level=level)\n",
    "            # Check correctness (simple check: does the answer contain the expected substring or exactly match).\n",
    "            # For numeric or single-word answers, exact match is fine. For sentences, we'll use substring or a small logic.\n",
    "            correct = False\n",
    "            # Normalize answer and expected for comparison:\n",
    "            ans_norm = answer.lower().strip()\n",
    "            exp_norm = str(expected).lower().strip()\n",
    "            # Simple heuristic: if expected answer is contained in the model answer text, we count it as correct.\n",
    "            if exp_norm in ans_norm or ans_norm in exp_norm:\n",
    "                correct = True\n",
    "            # Record the result\n",
    "            results.append({\n",
    "                \"question\": q_text,\n",
    "                \"level\": level,\n",
    "                \"model_answer\": answer,\n",
    "                \"correct\": correct,\n",
    "                \"total_tokens\": total_tokens,\n",
    "                \"reasoning_tokens\": reasoning_tokens\n",
    "            })\n",
    "        except TypeError as e:\n",
    "            print(f\"Error processing question '{q_text}' at level '{level}': {e}\")\n",
    "            results.append({\n",
    "                \"question\": q_text,\n",
    "                \"level\": level,\n",
    "                \"model_answer\": None,\n",
    "                \"correct\": False,\n",
    "                \"total_tokens\": None,\n",
    "                \"reasoning_tokens\": None \n",
    "            })\n",
    "\n",
    "# Convert results to DataFrame for analysis\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>level</th>\n",
       "      <th>model_answer</th>\n",
       "      <th>correct</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>reasoning_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>George wants to warm his hands quickly by rubb...</td>\n",
       "      <td>low</td>\n",
       "      <td>Rubbing dry skin creates a higher coefficient ...</td>\n",
       "      <td>True</td>\n",
       "      <td>242</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>George wants to warm his hands quickly by rubb...</td>\n",
       "      <td>medium</td>\n",
       "      <td>The answer is A: dry palms.\\n\\nExplanation: Wh...</td>\n",
       "      <td>True</td>\n",
       "      <td>473</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>George wants to warm his hands quickly by rubb...</td>\n",
       "      <td>high</td>\n",
       "      <td>Rubbing two surfaces together produces heat du...</td>\n",
       "      <td>True</td>\n",
       "      <td>936</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which of the following statements best explain...</td>\n",
       "      <td>low</td>\n",
       "      <td>The best explanation is that the refrigerator ...</td>\n",
       "      <td>True</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which of the following statements best explain...</td>\n",
       "      <td>medium</td>\n",
       "      <td>The best explanation is: B. The refrigerator d...</td>\n",
       "      <td>True</td>\n",
       "      <td>205</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Which of the following statements best explain...</td>\n",
       "      <td>high</td>\n",
       "      <td>The correct answer is B: The refrigerator door...</td>\n",
       "      <td>True</td>\n",
       "      <td>459</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question   level  \\\n",
       "0  George wants to warm his hands quickly by rubb...     low   \n",
       "1  George wants to warm his hands quickly by rubb...  medium   \n",
       "2  George wants to warm his hands quickly by rubb...    high   \n",
       "3  Which of the following statements best explain...     low   \n",
       "4  Which of the following statements best explain...  medium   \n",
       "5  Which of the following statements best explain...    high   \n",
       "\n",
       "                                        model_answer  correct  total_tokens  \\\n",
       "0  Rubbing dry skin creates a higher coefficient ...     True           242   \n",
       "1  The answer is A: dry palms.\\n\\nExplanation: Wh...     True           473   \n",
       "2  Rubbing two surfaces together produces heat du...     True           936   \n",
       "3  The best explanation is that the refrigerator ...     True           132   \n",
       "4  The best explanation is: B. The refrigerator d...     True           205   \n",
       "5  The correct answer is B: The refrigerator door...     True           459   \n",
       "\n",
       "   reasoning_tokens  \n",
       "0                64  \n",
       "1               320  \n",
       "2               768  \n",
       "3                 0  \n",
       "4                64  \n",
       "5               320  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>correct</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>reasoning_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high</td>\n",
       "      <td>1.0</td>\n",
       "      <td>697.5</td>\n",
       "      <td>544.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medium</td>\n",
       "      <td>1.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    level  correct  total_tokens  reasoning_tokens\n",
       "0    high      1.0         697.5             544.0\n",
       "1     low      1.0         187.0              32.0\n",
       "2  medium      1.0         339.0             192.0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aggregate the results by reasoning level\n",
    "df_results.groupby(\"level\").agg({\n",
    "    \"correct\": \"mean\",\n",
    "    \"total_tokens\": \"mean\",\n",
    "    \"reasoning_tokens\": \"mean\"\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompting practices:\n",
    "\n",
    " - Keep your prompt clear. For example, include context, choices (if applicable), and the question.\n",
    " - Use a consistent format to help the model interpret the query.\n",
    "\n",
    "\n",
    "### Reasoning Effort Levels:\n",
    "\n",
    " - \"low\": Minimal reasoning. Fast response time with lower token usage.\n",
    " - \"medium\": A balance between speed and detailed reasoning.\n",
    " - \"high\": Extensive reasoning, potentially yielding more accurate or nuanced answers, but at the cost of higher token usage and slower responses.\n",
    "\n",
    "### Response Time and Token Usage:\n",
    "\n",
    " - Monitor response time to gauge performance. For high-throughput applications, a lower reasoning effort might be preferable.\n",
    " - Analyze total_tokens and reasoning_tokens to optimize cost and model behavior.\n",
    "\n",
    "#### Logging and Error Handling:\n",
    "\n",
    " - Use try/except blocks to catch issues when processing multiple queries.\n",
    " - Logging errors can help you diagnose issues in real-world applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
