{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "446a6db5",
   "metadata": {},
   "source": [
    "## Choosing the right Reasoning model and Reasoning effort for your use case \n",
    "\n",
    "Reasoning models, such as OpenAI’s o1 and o3-mini, are advanced language models trained with reinforcement learning to enhance complex reasoning. They generate a detailed internal thought process before responding, making them highly effective in problem-solving, coding, scientific reasoning, and multi-step planning for agentic workflows.\n",
    "\n",
    "In this Cookbook, we will explore an Eval based quantiative analysis to help you choose the right reasoning model and reasoning effort for your use case. \n",
    "\n",
    "This is a 3 step process: \n",
    "\n",
    "1. Build Your Evaluation Dataset\n",
    "2. Build a Pipeline to evaluate the reasoning model and capture metrics \n",
    "3. Choose the model/parameter based on cost/performance trade-off "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8474d01e",
   "metadata": {},
   "source": [
    "### Step 1: Build Your Evaluation Dataset \n",
    "\n",
    "For this example, we will use the AI2-ARC dataset\n",
    "\n",
    "ARC-Challenge\n",
    "id: a string feature.\n",
    "question: a string feature.\n",
    "choices: a dictionary feature containing:\n",
    "text: a string feature.\n",
    "label: a string feature.\n",
    "answerKey: a string feature."
   ]
  },
  {
   "cell_type": "code",
   "id": "4b3867fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T19:26:42.747271Z",
     "start_time": "2025-02-18T19:26:41.922248Z"
    }
   },
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/ARC-Challenge/test-00000-of-00001.parquet\"\n",
    "response = requests.get(url)\n",
    "with open(\"test-00000-of-00001.parquet\", \"wb\") as f:\n",
    "    f.write(response.content)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "f0ad995b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T19:27:16.355444Z",
     "start_time": "2025-02-18T19:27:14.966383Z"
    }
   },
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Set Pandas options to display full text in cells\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Reads the Parquet file into a DataFrame.\n",
    "df = pd.read_parquet(\"test-00000-of-00001.parquet\")\n",
    "\n",
    "# Convert the first row to a dictionary.\n",
    "row_dict = df.head(1).iloc[0].to_dict()\n",
    "\n",
    "# Pretty-print the row as a JSON string with an indentation of 4 spaces.\n",
    "# The default lambda converts non-serializable objects (like numpy arrays) to lists.\n",
    "print(json.dumps(row_dict, indent=4, default=lambda o: o.tolist() if hasattr(o, 'tolist') else o))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"Mercury_7175875\",\n",
      "    \"question\": \"An astronomer observes that a planet rotates faster after a meteorite impact. Which is the most likely effect of this increase in rotation?\",\n",
      "    \"choices\": {\n",
      "        \"text\": [\n",
      "            \"Planetary density will decrease.\",\n",
      "            \"Planetary years will become longer.\",\n",
      "            \"Planetary days will become shorter.\",\n",
      "            \"Planetary gravity will become stronger.\"\n",
      "        ],\n",
      "        \"label\": [\n",
      "            \"A\",\n",
      "            \"B\",\n",
      "            \"C\",\n",
      "            \"D\"\n",
      "        ]\n",
      "    },\n",
      "    \"answerKey\": \"C\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "116e476a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T19:27:19.299931Z",
     "start_time": "2025-02-18T19:27:19.297453Z"
    }
   },
   "source": [
    "def display_total_rows(dataframe: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Display the total number of rows in the given DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        dataframe (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    total_rows = len(dataframe)\n",
    "    print(f\"Total number of rows in the dataset: {total_rows}\")\n",
    "\n",
    "# Display the total number of rows in the dataset\n",
    "display_total_rows(df)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in the dataset: 1172\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "380c8c4e",
   "metadata": {},
   "source": [
    "### Step 2: Build a Pipeline to evaluate the reasoning model and capture metrics \n",
    "\n",
    "Let's write a python script to evaluate the reasoning model and capture metrics. \n"
   ]
  },
  {
   "cell_type": "code",
   "id": "7a9b4bc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T19:34:45.497668Z",
     "start_time": "2025-02-18T19:34:45.471428Z"
    }
   },
   "source": [
    "import time \n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "def response_with_reasoning_effort(model: str, question: str, reasoning_effort: str):\n",
    "    \"\"\"\n",
    "    Send a question to the OpenAI model with a given reasoning effort level.\n",
    "\n",
    "    Parameters:\n",
    "        model (str): The name of the model.\n",
    "        question (str): The input prompt.\n",
    "        reasoning_effort (str): The reasoning effort level (\"low\", \"medium\", or \"high\").\n",
    "\n",
    "    Returns:\n",
    "        answer (str): The model's answer.\n",
    "        usage: The usage object containing token counts.\n",
    "        duration (float): Time taken for the API call.\n",
    "    \"\"\"\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # API Call\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        reasoning_effort=reasoning_effort,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that provides answe to multiple choice questions. Reply only with the letter of the correct answer choice.\"},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Extract answer from response.\n",
    "    answer = response.choices[0].message.content.strip()\n",
    "    usage = response.usage  # Contains prompt_tokens, total_tokens, and (optionally) reasoning_tokens.\n",
    "\n",
    "    return answer, usage, (end_time - start_time)\n"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "ca5ff73d",
   "metadata": {},
   "source": [
    "Run the pipeline for all the questions in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16bdbbc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "9589221b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T20:38:49.743199Z",
     "start_time": "2025-02-18T20:36:08.327963Z"
    }
   },
   "source": [
    "from tqdm import tqdm\n",
    "# List of models to iterate over\n",
    "models = [\"o3-mini\"]\n",
    "\n",
    "results = []  # to accumulate results for each question, model, and reasoning level\n",
    "\n",
    "# Assuming df is a DataFrame containing the questions, choices, answerKey, and id.\n",
    "for item in tqdm(range(20), desc=\"Processing Questions\"):\n",
    "    q_text = str(df.iloc[item].question) + \"\\n\" + \"choices: \" + str(df.iloc[item].choices)\n",
    "    expected = df.iloc[item].answerKey\n",
    "\n",
    "    for model in models:\n",
    "        for reasoning_effort in [\"low\", \"high\"]:\n",
    "            try:\n",
    "                answer, usage, duration = response_with_reasoning_effort(model, q_text, reasoning_effort)\n",
    "                correct = False\n",
    "                ans_norm = answer.lower().strip()\n",
    "                exp_norm = str(expected).lower().strip()\n",
    "\n",
    "                if exp_norm in ans_norm or ans_norm in exp_norm:\n",
    "                    correct = True\n",
    "\n",
    "                results.append({\n",
    "                    \"id\": df.iloc[item].id,\n",
    "                    \"model\": model,\n",
    "                    \"level\": reasoning_effort,\n",
    "                    \"model_answer\": answer,\n",
    "                    \"correct\": correct,\n",
    "                    \"prompt_tokens\": usage.prompt_tokens,\n",
    "                    \"total_tokens\": usage.total_tokens,\n",
    "                    \"reasoning_tokens\": usage.completion_tokens_details.reasoning_tokens,\n",
    "                    \"duration\": duration\n",
    "                })\n",
    "\n",
    "\n",
    "\n",
    "            except TypeError as e:\n",
    "                print(f\"Error processing question: {df.iloc[item].id} with model {model} at reasoning level {reasoning_effort}: {e}\")\n",
    "                # Skip this combination\n",
    "\n",
    "# Convert results to DataFrame for further analysis\n",
    "df_results = pd.DataFrame(results)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Questions: 100%|██████████| 20/20 [02:41<00:00,  8.07s/it]\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "45d88cc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T20:53:50.417889Z",
     "start_time": "2025-02-18T20:53:50.405599Z"
    }
   },
   "source": "print (df_results)\n",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   id    model level model_answer  correct  prompt_tokens  \\\n",
      "0     Mercury_7175875  o3-mini   low            C     True            127   \n",
      "1     Mercury_7175875  o3-mini  high            C     True            127   \n",
      "2   Mercury_SC_409171  o3-mini   low            B     True            142   \n",
      "3   Mercury_SC_409171  o3-mini  high            B     True            142   \n",
      "4   Mercury_SC_408547  o3-mini   low            C     True            133   \n",
      "5   Mercury_SC_408547  o3-mini  high            C     True            133   \n",
      "6      Mercury_407327  o3-mini   low            D     True            152   \n",
      "7      Mercury_407327  o3-mini  high            D     True            152   \n",
      "8      MCAS_2006_9_44  o3-mini   low            D     True            172   \n",
      "9      MCAS_2006_9_44  o3-mini  high            D     True            172   \n",
      "10    Mercury_7270393  o3-mini   low            B     True            174   \n",
      "11    Mercury_7270393  o3-mini  high            D    False            174   \n",
      "12      MCAS_2014_5_7  o3-mini   low            C     True            169   \n",
      "13      MCAS_2014_5_7  o3-mini  high            C     True            169   \n",
      "14    Mercury_7086660  o3-mini   low            C     True            136   \n",
      "15    Mercury_7086660  o3-mini  high            C     True            136   \n",
      "16    Mercury_7168805  o3-mini   low            B     True            162   \n",
      "17    Mercury_7168805  o3-mini  high            B     True            162   \n",
      "18     MCAS_2003_8_11  o3-mini   low            A     True            108   \n",
      "19     MCAS_2003_8_11  o3-mini  high            A     True            108   \n",
      "20    Mercury_7250058  o3-mini   low            B     True            121   \n",
      "21    Mercury_7250058  o3-mini  high            B     True            121   \n",
      "22    Mercury_7012740  o3-mini   low            A     True            117   \n",
      "23    Mercury_7012740  o3-mini  high            A     True            117   \n",
      "24   Mercury_LBS10610  o3-mini   low            C     True            119   \n",
      "25   Mercury_LBS10610  o3-mini  high            C     True            119   \n",
      "26  Mercury_SC_407400  o3-mini   low            C     True            122   \n",
      "27  Mercury_SC_407400  o3-mini  high            C     True            122   \n",
      "28    Mercury_7212993  o3-mini   low            C     True             98   \n",
      "29    Mercury_7212993  o3-mini  high            C     True             98   \n",
      "30  Mercury_SC_413240  o3-mini   low            A     True             93   \n",
      "31  Mercury_SC_413240  o3-mini  high            A     True             93   \n",
      "32    Mercury_7186358  o3-mini   low            C     True            156   \n",
      "33    Mercury_7186358  o3-mini  high            C     True            156   \n",
      "34    Mercury_7166425  o3-mini   low            B     True            142   \n",
      "35    Mercury_7166425  o3-mini  high            B     True            142   \n",
      "36      MDSA_2007_8_3  o3-mini   low            A     True            157   \n",
      "37      MDSA_2007_8_3  o3-mini  high            A     True            157   \n",
      "38    Mercury_7094290  o3-mini   low            C     True            130   \n",
      "39    Mercury_7094290  o3-mini  high            C     True            130   \n",
      "\n",
      "    total_tokens  reasoning_tokens   duration  \n",
      "0            139                 0   1.958233  \n",
      "1            330               192   3.708627  \n",
      "2            154                 0   1.426978  \n",
      "3            281               128   2.807160  \n",
      "4            208                64   2.042531  \n",
      "5            720               576   6.268056  \n",
      "6            164                 0   2.521268  \n",
      "7            355               192   3.587144  \n",
      "8            568               384   5.330822  \n",
      "9           1592              1408  14.747261  \n",
      "10           313               128   2.563352  \n",
      "11          1338              1152  16.329411  \n",
      "12           181                 0   2.091048  \n",
      "13           436               256   4.929702  \n",
      "14           147                 0   1.317473  \n",
      "15           211                64   2.482828  \n",
      "16           174                 0   2.096077  \n",
      "17           621               448   8.140244  \n",
      "18           119                 0   2.248430  \n",
      "19           375               256   4.112363  \n",
      "20           132                 0   2.179771  \n",
      "21           644               512   5.556823  \n",
      "22           128                 0   2.007906  \n",
      "23           704               576   7.623846  \n",
      "24           130                 0   2.216490  \n",
      "25           387               256   4.361448  \n",
      "26           261               128   3.319400  \n",
      "27           518               384   6.341139  \n",
      "28           109                 0   1.843552  \n",
      "29           237               128   3.928938  \n",
      "30           105                 0   1.669270  \n",
      "31           425               320   8.035731  \n",
      "32           168                 0   1.542220  \n",
      "33           296               128   3.522544  \n",
      "34           153                 0   1.522901  \n",
      "35           410               256   3.590194  \n",
      "36           168                 0   1.500855  \n",
      "37           360               192   3.278460  \n",
      "38           205                64   1.617122  \n",
      "39           526               384   4.979227  \n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "206f55d1",
   "metadata": {},
   "source": [
    "### Step 3: Choose the model/parameter based on cost/performance trade-off\n",
    "\n",
    "Let's plot a graph between accuracy and latency for each model/reasoning effort pair.\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ad3bcef8afa02971"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
