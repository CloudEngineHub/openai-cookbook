{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Basics with Agents SDK\n",
    "\n",
    "We recently launched the [Agents SDK](https://openai.github.io/openai-agents-python/) to make it easier to orchestrate agentic workflows. In this cookbook, we have'll some fun composing a Golf Agent that can help with creating personalized practice plans and also make score predictions for scores around you.\n",
    "\n",
    "- [Response API](https://platform.openai.com/docs/api-reference/responses)\n",
    "- [File Search API](https://platform.openai.com/docs/guides/tools-file-search)\n",
    "- [Web Search API](https://platform.openai.com/docs/guides/tools-web-search?api-mode=responses)\n",
    "\n",
    "## Agent Workflow\n",
    "\n",
    "For our design we divide the roles and resoponsibilities of agents by functionality. This architecture will help not only with dividing roles and responaibilities but also debugging and optimizations later on. Below are the following Agents and their scope \n",
    "\n",
    "![Local image](./Tee%20Time%20Finder.png)\n",
    "\n",
    "| Agent                          | Description                                                                                                                                                                                                                                             |\n",
    "|--------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Triage Agent                   | Responsible for understanding the user's initial intent and handing off to our other agents.                                                                                                                                                            |\n",
    "| Practice Planner Agent         | Responsible for constructing a personalized and detailed practice plan. This agent will have access to the FileSearch API to query for relevant user shot information.                                                                              |\n",
    "| Score Predictor & Course Finder | Responsible for finding nearby golf courses based on the user's request, making a score prediction for each golf course returned, and recommending club distance lengths for that day. This agent has access to both the FileSearch API and the WebSearch API. |\n",
    "\n",
    "\n",
    "## Data Preparation & Vector Store Population\n",
    "\n",
    "Before we can fire user requests into our Golf Agent, we need to upload the user's historical shot data into a Vector Store. Here is an example of the original golf data from a user's driving range practice session. \n",
    "\n",
    "| Date            | Player | Club Name | Club Type | Club Speed | Attack Angle | Club Path | Club Face | Face to Path | Ball Speed | Smash Factor | Launch Angle | Launch Direction | Backspin  | Sidespin  | Spin Rate | Spin Rate Type | Spin Axis | Apex Height | Carry Distance | Carry Deviation Angle | Carry Deviation Distance | Total Distance | Total Deviation Angle | Total Deviation Distance |\n",
    "|-----------------|--------|-----------|-----------|-------------|---------------|------------|------------|----------------|--------------|----------------|----------------|------------------|------------|------------|-------------|----------------|------------|--------------|----------------|------------------------|--------------------------|----------------|------------------------|--------------------------|\n",
    "| 1/4/25 17:01:39 | Brian  |           | 7 Iron    | 74.02      | 2.68         | 5.99      | 10.18     | 4.19           | 100.39      | 1.36           | 20.67         | 9.11              | 3501.39   | -366.16   | 3520.48    | Measured      | 5.97       | 22.77        | 143.31         | 11.92                  | 29.59                    | 156.29         | 12.01                  | 32.52                    |\n",
    "| 1/4/25 17:02:08 | Brian  |           | 7 Iron    | 75.85      | -3.13        | 3.87      | 5.76      | 1.89           | 100.17      | 1.32           | 18.06         | 5.22              | 3549.35   | 61.95     | 3549.89    | Measured      | -1.0       | 19.23        | 140.03         | 5.18                   | 12.63                    | 154.17         | 5.11                   | 13.74                    |\n",
    "| 1/4/25 17:02:52 | Jason  |           | 7 Iron    | 75.74      | -4.96        | 7.18      | 5.95      | -1.23          | 87.15       | 1.15           | 12.74         | 5.79              | 2423.86   | 1189.54   | 2700.02    | Estimated     | -26.14     | 6.79         | 91.81          | 0.92                   | 1.47                     | 122.10         | -0.35                  | -0.75                    |\n",
    "| 1/4/25 17:03:49 | Herald |           | 7 Iron    | 75.99      | 4.53         | 5.91      | 5.20      | -0.71          | 96.95       | 1.28           | 14.49         | 5.01              | 4544.12   | -699.41   | 4597.63    | Measured      | 8.75       | 13.98        | 124.95         | 8.29                   | 18.01                    | 138.91         | 8.55                   | 20.66                    |\n",
    "| 1/4/25 17:04:58 | Jason  |           | 7 Iron    | 77.08      | 7.36         | 3.77      | 3.15      | -0.62          | 102.56      | 1.33           |               | 3.06              | 1918.64   | 0.00      | 1918.64    | Measured      | 0.00       |              |                 |                         |                          |                |                        |                          |\n",
    "| 1/4/25 17:05:42 | Brian  |           | 7 Iron    | 34.29      | 0.00         | 0.00      | 0.00      | 0.00           | 41.41       | 1.21           | 17.26         | -2.19             | 3052.55   | 0.00      | 3052.55    | Estimated     | 0.00       | 2.00         | 23.61          | -2.21                  | -0.91                    | 29.05          | -2.21                  | -1.12                    |\n",
    "| 1/4/25 17:08:56 | Jason  |           | 7 Iron    | 75.77      | -4.19        | 6.90      | 10.15     | 3.25           | 98.76       | 1.30           | 19.33         | 9.20              | 5117.86   | 573.16    | 5149.85    | Measured      | -6.39      | 21.80        | 133.79         | 7.32                   | 17.04                    | 143.50         | 7.09                   | 17.72                    |\n",
    "| 1/4/25 17:09:17 | Brian  |           | 7 Iron    | 76.39      | 2.79         | 3.26      | 6.68      | 3.42           | 104.35      | 1.37           | 15.02         | 5.89              | 3443.57   | -523.87   | 3483.19    | Measured      | 8.65       | 16.47        | 143.91         | 9.10                   | 22.75                    | 159.72         | 9.34                   | 25.93                    |\n",
    "| 1/4/25 17:09:48 | Jason  |           | 7 Iron    | 76.35      | 0.35         | 2.09      | 6.56      | 4.47           | 102.63      | 1.34           | 14.20         | 5.65              | 5386.30   | -1082.16  | 5493.93    | Measured      | 11.36      | 16.61        | 135.01         | 10.57                  | 24.77                    | 146.59         | 10.88                  | 27.67                    |\n",
    "| 1/4/25 17:10:26 | Lauren |           | 7 Iron    | 77.78      | 4.00         | 8.51      | 9.90      | 1.39           | 99.70       | 1.28           | 17.16         | 9.20              | 4462.13   | -68.54    | 4462.66    | Measured      | 0.88       | 18.77        | 135.86         | 10.13                  | 23.90                    | 147.86         | 10.09                  | 25.91                    |\n",
    "\n",
    "\n",
    "In the perfect world, if we were a serious golfer, we could have added to the Note and Tag fields to writedown specific observations from each of these shots while practicing. Therefore, we're going to enrich this data by using a LLM to provide detailed shot feedback for each shot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Preparation\n",
    "In this step, we read the input CSV files, process them by combining header and unit information, and save the processed files for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/jhall/.pyenv/versions/3.11.8/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: openai in /Users/jhall/.pyenv/versions/3.11.8/lib/python3.11/site-packages (1.66.3)\n",
      "Requirement already satisfied: tqdm in /Users/jhall/.pyenv/versions/3.11.8/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: dotenv in /Users/jhall/.pyenv/versions/3.11.8/lib/python3.11/site-packages (0.9.9)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Users/jhall/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pandas) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jhall/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jhall/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/jhall/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/jhall/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/jhall/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/jhall/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/jhall/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/jhall/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /Users/jhall/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/jhall/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: python-dotenv in /Users/jhall/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from dotenv) (1.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/jhall/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/jhall/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/jhall/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/jhall/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/jhall/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/jhall/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jhall/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas openai tqdm dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "client = OpenAI()\n",
    "tqdm.pandas()  # Enable progress_apply for pandas operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [03:36<00:00,  2.77s/it]:00<?, ?it/s]\n",
      "Processing CSV files:   8%|▊         | 1/13 [03:36<43:14, 216.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to /Users/jhall/code/openai-cookbook/examples/agents_sdk/basics_of_agents_sdk/data/processed/Golf_Shot_Data_9.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [04:39<00:00,  2.11s/it]\n",
      "Processing CSV files:  15%|█▌        | 2/13 [08:15<46:25, 253.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to /Users/jhall/code/openai-cookbook/examples/agents_sdk/basics_of_agents_sdk/data/processed/Golf_Shot_Data_8.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [05:46<00:00,  3.06s/it]\n",
      "Processing CSV files:  23%|██▎       | 3/13 [14:01<49:16, 295.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to /Users/jhall/code/openai-cookbook/examples/agents_sdk/basics_of_agents_sdk/data/processed/Golf_Shot_Data_10.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [02:00<00:00,  2.28s/it]\n",
      "Processing CSV files:  31%|███       | 4/13 [16:02<33:59, 226.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to /Users/jhall/code/openai-cookbook/examples/agents_sdk/basics_of_agents_sdk/data/processed/Golf_Shot_Data_12.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [01:16<00:00,  1.95s/it]\n",
      "Processing CSV files:  38%|███▊      | 5/13 [17:18<22:59, 172.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to /Users/jhall/code/openai-cookbook/examples/agents_sdk/basics_of_agents_sdk/data/processed/Golf_Shot_Data_13.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [01:05<00:00,  1.93s/it]\n",
      "Processing CSV files:  46%|████▌     | 6/13 [18:23<15:52, 136.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to /Users/jhall/code/openai-cookbook/examples/agents_sdk/basics_of_agents_sdk/data/processed/Golf_Shot_Data_0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [04:10<00:00,  2.48s/it]\n",
      "Processing CSV files:  54%|█████▍    | 7/13 [22:34<17:21, 173.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to /Users/jhall/code/openai-cookbook/examples/agents_sdk/basics_of_agents_sdk/data/processed/Golf_Shot_Data_1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [01:59<00:00,  2.18s/it]\n",
      "Processing CSV files:  62%|██████▏   | 8/13 [24:34<13:02, 156.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to /Users/jhall/code/openai-cookbook/examples/agents_sdk/basics_of_agents_sdk/data/processed/Golf_Shot_Data_3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [03:12<00:00,  2.29s/it]\n",
      "Processing CSV files:  69%|██████▉   | 9/13 [27:47<11:10, 167.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to /Users/jhall/code/openai-cookbook/examples/agents_sdk/basics_of_agents_sdk/data/processed/Golf_Shot_Data_2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [02:45<00:00,  2.44s/it]\n",
      "Processing CSV files:  77%|███████▋  | 10/13 [30:32<08:21, 167.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to /Users/jhall/code/openai-cookbook/examples/agents_sdk/basics_of_agents_sdk/data/processed/Golf_Shot_Data_6.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [04:47<00:00,  2.18s/it]\n",
      "Processing CSV files:  85%|████████▍ | 11/13 [35:20<06:48, 204.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to /Users/jhall/code/openai-cookbook/examples/agents_sdk/basics_of_agents_sdk/data/processed/Golf_Shot_Data_7.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [02:25<00:00,  2.35s/it]\n",
      "Processing CSV files:  92%|█████████▏| 12/13 [37:46<03:06, 186.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to /Users/jhall/code/openai-cookbook/examples/agents_sdk/basics_of_agents_sdk/data/processed/Golf_Shot_Data_5.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [02:18<00:00,  2.06s/it]\n",
      "Processing CSV files: 100%|██████████| 13/13 [40:04<00:00, 184.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to /Users/jhall/code/openai-cookbook/examples/agents_sdk/basics_of_agents_sdk/data/processed/Golf_Shot_Data_4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_INSTRUCTIONS = \"\"\"\n",
    "You are a professional and very popular golf instructor with years of experience. You have a deep understanding of a variety of golf drills and exercises that can help golfers improve their game. You excel at synthesizing complex golf metrics from launch monitors and distilling them into comprehensible and actionable feedback and tips without being too technical. Convert it into lamens terms for high handicappers.\n",
    "\"\"\"\n",
    "\n",
    "def generate_feedback(row):\n",
    "    prompt = f\"\"\"\n",
    "    Review the following shot data and provide concise feedback:\n",
    "\n",
    "    Date: {row.get('Date', 'N/A')}\n",
    "    Club Type: {row.get('Club Type', 'N/A')}\n",
    "    Club Speed: {row.get('Club Speed', 'N/A')} mph\n",
    "    Attack Angle: {row.get('Attack Angle', 'N/A')} degrees\n",
    "    Club Path: {row.get('Club Path', 'N/A')} degrees\n",
    "    Club Face: {row.get('Club Face', 'N/A')} degrees\n",
    "    Face To Path: {row.get('Face To Path', 'N/A')} degrees\n",
    "    Ball Speed: {row.get('Ball Speed', 'N/A')} mph\n",
    "    Smash Factor: {row.get('Smash Factor', 'N/A')}\n",
    "    Launch Angle: {row.get('Launch Angle', 'N/A')} degrees\n",
    "    Launch Direction: {row.get('Launch Direction', 'N/A')} degrees\n",
    "    Backspin: {row.get('Backspin', 'N/A')} rpm\n",
    "    Sidespin: {row.get('Sidespin', 'N/A')} rpm\n",
    "    Spin Rate: {row.get('Spin Rate', 'N/A')} rpm\n",
    "    Spin Rate Type: {row.get('Spin Rate Type', 'N/A')}\n",
    "    Spin Axis: {row.get('Spin Axis', 'N/A')} degrees\n",
    "    Apex Height: {row.get('Apex Height', 'N/A')} yards\n",
    "    Carry Distance: {row.get('Carry Distance', 'N/A')} yards\n",
    "    Carry Deviation Angle: {row.get('Carry Deviation Angle', 'N/A')} degrees\n",
    "    Carry Deviation Distance: {row.get('Carry Deviation Distance', 'N/A')} yards\n",
    "    Total Distance: {row.get('Total Distance', 'N/A')} yards\n",
    "    Total Deviation Angle: {row.get('Total Deviation Angle', 'N/A')} degrees\n",
    "    Total Deviation Distance: {row.get('Total Deviation Distance', 'N/A')} yards\n",
    "    Note: {row.get('Note', 'N/A')}\n",
    "    Tag: {row.get('Tag', 'N/A')}\n",
    "    Air Density: {row.get('Air Density', 'N/A')} g/L\n",
    "    Temperature: {row.get('Temperature', 'N/A')} °F\n",
    "    Air Pressure: {row.get('Air Pressure', 'N/A')} kPa\n",
    "    Relative Humidity: {row.get('Relative Humidity', 'N/A')}%\n",
    "\n",
    "    Provide brief feedback and a short tag describing a drill that the golfer can do to improve their game such as \"step through drill\", \"swing path drill\", \"slow motion swing\", \"shoulder turn check\", \"half swing pause\", etc.\n",
    "    Format your response as JSON:\n",
    "    {{\n",
    "        \"feedback\": \"Your feedback here\",\n",
    "        \"tag\": \"Your tag here\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_INSTRUCTIONS},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        text={\n",
    "            \"format\": {\n",
    "                \"type\": \"json_object\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    result = response.output_text\n",
    "    return pd.Series(eval(result))\n",
    "\n",
    "def process_and_enrich_csv(filepath, output_filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    feedback_tags = df.progress_apply(generate_feedback, axis=1)\n",
    "    df['Note'] = feedback_tags['feedback']\n",
    "    df['Tag'] = feedback_tags['tag']\n",
    "    df.to_csv(output_filepath, index=False)\n",
    "    print(f\"Updated CSV saved to {output_filepath}\")\n",
    "\n",
    "data_folder = os.path.join(os.path.dirname(os.getcwd()), \"basics_of_agents_sdk/data\")\n",
    "raw_data_folder = os.path.join(data_folder, 'raw')\n",
    "enriched_data_folder = os.path.join(data_folder, 'processed')\n",
    "\n",
    "# Loop through each CSV file in the raw data folder with a progress bar\n",
    "for filename in tqdm(os.listdir(raw_data_folder), desc=\"Processing CSV files\"):\n",
    "    if filename.endswith('.csv'):\n",
    "        csv_path = os.path.join(raw_data_folder, filename)\n",
    "        output_filepath = os.path.join(enriched_data_folder, filename)\n",
    "        process_and_enrich_csv(csv_path, output_filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Uploading to File Search API (Vector Store)\n",
    "In this step, each row of the enriched CSV is uploaded as an embedding to the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "def upload_chunks_from_file(file_name, data_folder, purpose, max_retries=3, backoff_factor=2, use_cache=False):\n",
    "    filepath = os.path.join(data_folder, file_name)\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"File {file_name} does not exist in {data_folder}.\")\n",
    "        return {}\n",
    "    df = pd.read_csv(filepath)\n",
    "    chunk_file_ids = {}\n",
    "    cache_path = os.path.join(data_folder, f\"{os.path.splitext(file_name)[0]}_upload_cache.json\")\n",
    "    if use_cache and os.path.exists(cache_path):\n",
    "        with open(cache_path, 'r', encoding='utf-8') as cache_file:\n",
    "            upload_cache = json.load(cache_file)\n",
    "    else:\n",
    "        upload_cache = {}\n",
    "    for i, row in df.iterrows():\n",
    "        temp_chunk_filename = os.path.splitext(file_name)[0] + f\"_chunk_{i}.txt\"\n",
    "        if use_cache and temp_chunk_filename in upload_cache:\n",
    "            chunk_file_ids[temp_chunk_filename] = upload_cache[temp_chunk_filename]\n",
    "            # print(f\"Skipping chunk {i} of {file_name}; already uploaded.\")\n",
    "            continue\n",
    "        chunk_text = row.to_json()\n",
    "        temp_chunk_filepath = os.path.join(data_folder, temp_chunk_filename)\n",
    "        with open(temp_chunk_filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(chunk_text)\n",
    "        chunk_file_id = None\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                with open(temp_chunk_filepath, 'rb') as f:\n",
    "                    response = client.files.create(file=f, purpose=purpose)\n",
    "                chunk_file_id = response.id\n",
    "                # print(f\"Uploaded chunk {i} of {file_name} with id: {chunk_file_id}\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                sleep_time = backoff_factor * (2 ** attempt) + random.uniform(0, 0.1)\n",
    "                print(f\"Attempt {attempt+1} failed for chunk {i} of {file_name}: {e}\")\n",
    "                time.sleep(sleep_time)\n",
    "        if chunk_file_id:\n",
    "            chunk_file_ids[temp_chunk_filename] = chunk_file_id\n",
    "            if use_cache:\n",
    "                upload_cache[temp_chunk_filename] = chunk_file_id\n",
    "                with open(cache_path, 'w', encoding='utf-8') as cache_file:\n",
    "                    json.dump(upload_cache, cache_file)\n",
    "        else:\n",
    "            print(f\"Failed to upload chunk {i} of {file_name} after {max_retries} attempts.\")\n",
    "        os.remove(temp_chunk_filepath)\n",
    "    return chunk_file_ids\n",
    "\n",
    "def upload_all_ready_chunks(data_folder, purpose='user_data'):\n",
    "    all_chunk_ids = {}\n",
    "    for file_name in tqdm(os.listdir(data_folder), desc='Processing CSV files'):\n",
    "        if file_name.endswith('.csv'):\n",
    "            chunk_ids = upload_chunks_from_file(file_name, data_folder, purpose, use_cache=True)\n",
    "            if chunk_ids:\n",
    "                all_chunk_ids[file_name] = chunk_ids\n",
    "    # print('All uploaded chunk file IDs:')\n",
    "    # for original_file, chunks in all_chunk_ids.items():\n",
    "    #     # print(f\"{original_file}:\")\n",
    "    #     for chunk_filename, chunk_id in chunks.items():\n",
    "    #         print(f\"    {chunk_filename}: {chunk_id}\")\n",
    "    return all_chunk_ids\n",
    "\n",
    "def chunk_list(input_list, chunk_size):\n",
    "    \"\"\"Splits a list into smaller chunks.\"\"\"\n",
    "    return [input_list[i:i + chunk_size] for i in range(0, len(input_list), chunk_size)]\n",
    "\n",
    "\n",
    "def upload_to_vector_store(all_chunk_ids, vector_store_id, chunk_size=500):\n",
    "    all_file_ids = [chunk_id for file_chunks in all_chunk_ids.values() for chunk_id in file_chunks.values()]\n",
    "    file_id_batches = chunk_list(all_file_ids, chunk_size)\n",
    "    for idx, batch in enumerate(file_id_batches):\n",
    "        vector_store_batch = client.vector_stores.file_batches.create(\n",
    "            file_ids=batch,\n",
    "            vector_store_id=vector_store_id\n",
    "        )\n",
    "        print(f\"Uploaded batch {idx + 1}/{len(file_id_batches)}: {vector_store_batch.id}, Status: {vector_store_batch.status}\")\n",
    "\n",
    "print(os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "# SHOT_DATA_VECTOR_STORE_ID = os.getenv('SHOT_DATA_VECTOR_STORE_ID')\n",
    "# data_folder = os.path.join(os.path.dirname(os.getcwd()), \"basics_of_agents_sdk/data\")\n",
    "# enriched_data_folder = os.path.join(data_folder, 'processed')\n",
    "# all_chunk_ids = upload_all_ready_chunks(enriched_data_folder)\n",
    "# upload_to_vector_store(all_chunk_ids, SHOT_DATA_VECTOR_STORE_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
