{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Basics with Agents SDK\n",
    "\n",
    "We recently launched the [Agents SDK](https://openai.github.io/openai-agents-python/) to make it easier to orchestrate agentic workflows. In this cookbook, we have'll some fun composing a Golf Agent that can help with creating personalized practice plans and also make score predictions for scores around you.\n",
    "\n",
    "- [Response API](https://platform.openai.com/docs/api-reference/responses)\n",
    "- [File Search API](https://platform.openai.com/docs/guides/tools-file-search)\n",
    "- [Web Search API](https://platform.openai.com/docs/guides/tools-web-search?api-mode=responses)\n",
    "\n",
    "## Agent Workflow\n",
    "\n",
    "For our design we divide the roles and resoponsibilities of agents by functionality. This architecture will help not only with dividing roles and responaibilities but also debugging and optimizations later on. Below are the following Agents and their scope \n",
    "\n",
    "![Local image](./Tee%20Time%20Finder.png)\n",
    "\n",
    "| Agent                          | Description                                                                                                                                                                                                                                             |\n",
    "|--------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Triage Agent                   | Responsible for understanding the user's initial intent and handing off to our other agents.                                                                                                                                                            |\n",
    "| Practice Planner Agent         | Responsible for constructing a personalized and detailed practice plan. This agent will have access to the FileSearch API to query for relevant user shot information.                                                                              |\n",
    "| Score Predictor & Course Finder | Responsible for finding nearby golf courses based on the user's request, making a score prediction for each golf course returned, and recommending club distance lengths for that day. This agent has access to both the FileSearch API and the WebSearch API. |\n",
    "\n",
    "\n",
    "## Data Preparation & Vector Store Population\n",
    "\n",
    "Before we can fire user requests into our Golf Agent, we need to upload the user's historical shot data into a Vector Store. Here is an example of the original golf data from a user's driving range practice session. \n",
    "\n",
    "| Date            | Player | Club Name | Club Type | Club Speed | Attack Angle | Club Path | Club Face | Face to Path | Ball Speed | Smash Factor | Launch Angle | Launch Direction | Backspin  | Sidespin  | Spin Rate | Spin Rate Type | Spin Axis | Apex Height | Carry Distance | Carry Deviation Angle | Carry Deviation Distance | Total Distance | Total Deviation Angle | Total Deviation Distance |\n",
    "|-----------------|--------|-----------|-----------|-------------|---------------|------------|------------|----------------|--------------|----------------|----------------|------------------|------------|------------|-------------|----------------|------------|--------------|----------------|------------------------|--------------------------|----------------|------------------------|--------------------------|\n",
    "| 1/4/25 17:01:39 | Brian  |           | 7 Iron    | 74.02      | 2.68         | 5.99      | 10.18     | 4.19           | 100.39      | 1.36           | 20.67         | 9.11              | 3501.39   | -366.16   | 3520.48    | Measured      | 5.97       | 22.77        | 143.31         | 11.92                  | 29.59                    | 156.29         | 12.01                  | 32.52                    |\n",
    "| 1/4/25 17:02:08 | Brian  |           | 7 Iron    | 75.85      | -3.13        | 3.87      | 5.76      | 1.89           | 100.17      | 1.32           | 18.06         | 5.22              | 3549.35   | 61.95     | 3549.89    | Measured      | -1.0       | 19.23        | 140.03         | 5.18                   | 12.63                    | 154.17         | 5.11                   | 13.74                    |\n",
    "| 1/4/25 17:02:52 | Jason  |           | 7 Iron    | 75.74      | -4.96        | 7.18      | 5.95      | -1.23          | 87.15       | 1.15           | 12.74         | 5.79              | 2423.86   | 1189.54   | 2700.02    | Estimated     | -26.14     | 6.79         | 91.81          | 0.92                   | 1.47                     | 122.10         | -0.35                  | -0.75                    |\n",
    "| 1/4/25 17:03:49 | Herald |           | 7 Iron    | 75.99      | 4.53         | 5.91      | 5.20      | -0.71          | 96.95       | 1.28           | 14.49         | 5.01              | 4544.12   | -699.41   | 4597.63    | Measured      | 8.75       | 13.98        | 124.95         | 8.29                   | 18.01                    | 138.91         | 8.55                   | 20.66                    |\n",
    "| 1/4/25 17:04:58 | Jason  |           | 7 Iron    | 77.08      | 7.36         | 3.77      | 3.15      | -0.62          | 102.56      | 1.33           |               | 3.06              | 1918.64   | 0.00      | 1918.64    | Measured      | 0.00       |              |                 |                         |                          |                |                        |                          |\n",
    "| 1/4/25 17:05:42 | Brian  |           | 7 Iron    | 34.29      | 0.00         | 0.00      | 0.00      | 0.00           | 41.41       | 1.21           | 17.26         | -2.19             | 3052.55   | 0.00      | 3052.55    | Estimated     | 0.00       | 2.00         | 23.61          | -2.21                  | -0.91                    | 29.05          | -2.21                  | -1.12                    |\n",
    "| 1/4/25 17:08:56 | Jason  |           | 7 Iron    | 75.77      | -4.19        | 6.90      | 10.15     | 3.25           | 98.76       | 1.30           | 19.33         | 9.20              | 5117.86   | 573.16    | 5149.85    | Measured      | -6.39      | 21.80        | 133.79         | 7.32                   | 17.04                    | 143.50         | 7.09                   | 17.72                    |\n",
    "| 1/4/25 17:09:17 | Brian  |           | 7 Iron    | 76.39      | 2.79         | 3.26      | 6.68      | 3.42           | 104.35      | 1.37           | 15.02         | 5.89              | 3443.57   | -523.87   | 3483.19    | Measured      | 8.65       | 16.47        | 143.91         | 9.10                   | 22.75                    | 159.72         | 9.34                   | 25.93                    |\n",
    "| 1/4/25 17:09:48 | Jason  |           | 7 Iron    | 76.35      | 0.35         | 2.09      | 6.56      | 4.47           | 102.63      | 1.34           | 14.20         | 5.65              | 5386.30   | -1082.16  | 5493.93    | Measured      | 11.36      | 16.61        | 135.01         | 10.57                  | 24.77                    | 146.59         | 10.88                  | 27.67                    |\n",
    "| 1/4/25 17:10:26 | Lauren |           | 7 Iron    | 77.78      | 4.00         | 8.51      | 9.90      | 1.39           | 99.70       | 1.28           | 17.16         | 9.20              | 4462.13   | -68.54    | 4462.66    | Measured      | 0.88       | 18.77        | 135.86         | 10.13                  | 23.90                    | 147.86         | 10.09                  | 25.91                    |\n",
    "\n",
    "\n",
    "In the perfect world, if we were a serious golfer, we could have added to the Note and Tag fields to writedown specific observations from each of these shots while practicing. Therefore, we're going to enrich this data by using a LLM to provide detailed shot feedback for each shot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Setup Your Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./dev/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: openai in ./dev/lib/python3.11/site-packages (1.66.3)\n",
      "Requirement already satisfied: tqdm in ./dev/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: dotenv in ./dev/lib/python3.11/site-packages (0.9.9)\n",
      "Requirement already satisfied: openai-agents in ./dev/lib/python3.11/site-packages (0.0.4)\n",
      "Requirement already satisfied: ipywidgets in ./dev/lib/python3.11/site-packages (8.1.5)\n",
      "Collecting jupyter_contrib_nbextensions\n",
      "  Downloading jupyter_contrib_nbextensions-0.7.0.tar.gz (23.5 MB)\n",
      "     l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/23.5 MB ? eta -:--:--━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━ 22.8/23.5 MB 117.6 MB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.5/23.5 MB 106.4 MB/s eta 0:00:00\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23.2 in ./dev/lib/python3.11/site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./dev/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./dev/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./dev/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./dev/lib/python3.11/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./dev/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./dev/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./dev/lib/python3.11/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./dev/lib/python3.11/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in ./dev/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./dev/lib/python3.11/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: python-dotenv in ./dev/lib/python3.11/site-packages (from dotenv) (1.0.1)\n",
      "Requirement already satisfied: griffe<2,>=1.5.6 in ./dev/lib/python3.11/site-packages (from openai-agents) (1.6.0)\n",
      "Requirement already satisfied: requests<3,>=2.0 in ./dev/lib/python3.11/site-packages (from openai-agents) (2.32.3)\n",
      "Requirement already satisfied: types-requests<3,>=2.0 in ./dev/lib/python3.11/site-packages (from openai-agents) (2.32.0.20250306)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./dev/lib/python3.11/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./dev/lib/python3.11/site-packages (from ipywidgets) (9.0.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./dev/lib/python3.11/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in ./dev/lib/python3.11/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in ./dev/lib/python3.11/site-packages (from ipywidgets) (3.0.13)\n",
      "Collecting ipython_genutils (from jupyter_contrib_nbextensions)\n",
      "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl.metadata (755 bytes)\n",
      "Collecting jupyter_contrib_core>=0.3.3 (from jupyter_contrib_nbextensions)\n",
      "  Downloading jupyter_contrib_core-0.4.2.tar.gz (17 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: jupyter_core in ./dev/lib/python3.11/site-packages (from jupyter_contrib_nbextensions) (5.7.2)\n",
      "Collecting jupyter_highlight_selected_word>=0.1.1 (from jupyter_contrib_nbextensions)\n",
      "  Downloading jupyter_highlight_selected_word-0.2.0-py2.py3-none-any.whl.metadata (730 bytes)\n",
      "Collecting jupyter_nbextensions_configurator>=0.4.0 (from jupyter_contrib_nbextensions)\n",
      "  Downloading jupyter_nbextensions_configurator-0.6.4-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nbconvert>=6.0 in ./dev/lib/python3.11/site-packages (from jupyter_contrib_nbextensions) (7.16.6)\n",
      "Requirement already satisfied: notebook>=6.0 in ./dev/lib/python3.11/site-packages (from jupyter_contrib_nbextensions) (7.3.3)\n",
      "Requirement already satisfied: tornado in ./dev/lib/python3.11/site-packages (from jupyter_contrib_nbextensions) (6.4.2)\n",
      "Collecting lxml (from jupyter_contrib_nbextensions)\n",
      "  Using cached lxml-5.3.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: idna>=2.8 in ./dev/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: colorama>=0.4 in ./dev/lib/python3.11/site-packages (from griffe<2,>=1.5.6->openai-agents) (0.4.6)\n",
      "Requirement already satisfied: certifi in ./dev/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in ./dev/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./dev/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: decorator in ./dev/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./dev/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./dev/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./dev/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./dev/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./dev/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./dev/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in ./dev/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: setuptools in ./dev/lib/python3.11/site-packages (from jupyter_contrib_core>=0.3.3->jupyter_contrib_nbextensions) (65.5.0)\n",
      "Requirement already satisfied: jupyter-server in ./dev/lib/python3.11/site-packages (from jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (2.15.0)\n",
      "Requirement already satisfied: pyyaml in ./dev/lib/python3.11/site-packages (from jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (6.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in ./dev/lib/python3.11/site-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (4.13.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in ./dev/lib/python3.11/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.0->jupyter_contrib_nbextensions) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in ./dev/lib/python3.11/site-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (0.7.1)\n",
      "Requirement already satisfied: jinja2>=3.0 in ./dev/lib/python3.11/site-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (3.1.6)\n",
      "Requirement already satisfied: jupyterlab-pygments in ./dev/lib/python3.11/site-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in ./dev/lib/python3.11/site-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (3.0.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in ./dev/lib/python3.11/site-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (3.1.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in ./dev/lib/python3.11/site-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (0.10.2)\n",
      "Requirement already satisfied: nbformat>=5.7 in ./dev/lib/python3.11/site-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (5.10.4)\n",
      "Requirement already satisfied: packaging in ./dev/lib/python3.11/site-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (24.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in ./dev/lib/python3.11/site-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (1.5.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./dev/lib/python3.11/site-packages (from jupyter_core->jupyter_contrib_nbextensions) (4.3.6)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in ./dev/lib/python3.11/site-packages (from notebook>=6.0->jupyter_contrib_nbextensions) (2.27.3)\n",
      "Requirement already satisfied: jupyterlab<4.4,>=4.3.6 in ./dev/lib/python3.11/site-packages (from notebook>=6.0->jupyter_contrib_nbextensions) (4.3.6)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in ./dev/lib/python3.11/site-packages (from notebook>=6.0->jupyter_contrib_nbextensions) (0.2.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./dev/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./dev/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in ./dev/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./dev/lib/python3.11/site-packages (from requests<3,>=2.0->openai-agents) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./dev/lib/python3.11/site-packages (from requests<3,>=2.0->openai-agents) (2.3.0)\n",
      "Requirement already satisfied: webencodings in ./dev/lib/python3.11/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.0->jupyter_contrib_nbextensions) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in ./dev/lib/python3.11/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.0->jupyter_contrib_nbextensions) (1.4.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./dev/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in ./dev/lib/python3.11/site-packages (from jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (23.1.0)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in ./dev/lib/python3.11/site-packages (from jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (8.6.3)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in ./dev/lib/python3.11/site-packages (from jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in ./dev/lib/python3.11/site-packages (from jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (0.5.3)\n",
      "Requirement already satisfied: overrides>=5.0 in ./dev/lib/python3.11/site-packages (from jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in ./dev/lib/python3.11/site-packages (from jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (0.21.1)\n",
      "Requirement already satisfied: pyzmq>=24 in ./dev/lib/python3.11/site-packages (from jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (26.3.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in ./dev/lib/python3.11/site-packages (from jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in ./dev/lib/python3.11/site-packages (from jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in ./dev/lib/python3.11/site-packages (from jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in ./dev/lib/python3.11/site-packages (from jupyterlab<4.4,>=4.3.6->notebook>=6.0->jupyter_contrib_nbextensions) (2.0.4)\n",
      "Requirement already satisfied: ipykernel>=6.5.0 in ./dev/lib/python3.11/site-packages (from jupyterlab<4.4,>=4.3.6->notebook>=6.0->jupyter_contrib_nbextensions) (6.29.5)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in ./dev/lib/python3.11/site-packages (from jupyterlab<4.4,>=4.3.6->notebook>=6.0->jupyter_contrib_nbextensions) (2.2.5)\n",
      "Requirement already satisfied: babel>=2.10 in ./dev/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=6.0->jupyter_contrib_nbextensions) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in ./dev/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=6.0->jupyter_contrib_nbextensions) (0.10.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in ./dev/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=6.0->jupyter_contrib_nbextensions) (4.23.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in ./dev/lib/python3.11/site-packages (from nbformat>=5.7->nbconvert>=6.0->jupyter_contrib_nbextensions) (2.21.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./dev/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./dev/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./dev/lib/python3.11/site-packages (from beautifulsoup4->nbconvert>=6.0->jupyter_contrib_nbextensions) (2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./dev/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./dev/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./dev/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: argon2-cffi-bindings in ./dev/lib/python3.11/site-packages (from argon2-cffi>=21.1->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (21.2.0)\n",
      "Requirement already satisfied: appnope in ./dev/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab<4.4,>=4.3.6->notebook>=6.0->jupyter_contrib_nbextensions) (0.1.4)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./dev/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab<4.4,>=4.3.6->notebook>=6.0->jupyter_contrib_nbextensions) (1.8.13)\n",
      "Requirement already satisfied: nest-asyncio in ./dev/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab<4.4,>=4.3.6->notebook>=6.0->jupyter_contrib_nbextensions) (1.6.0)\n",
      "Requirement already satisfied: psutil in ./dev/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab<4.4,>=4.3.6->notebook>=6.0->jupyter_contrib_nbextensions) (7.0.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./dev/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=6.0->jupyter_contrib_nbextensions) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./dev/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=6.0->jupyter_contrib_nbextensions) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./dev/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=6.0->jupyter_contrib_nbextensions) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./dev/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=6.0->jupyter_contrib_nbextensions) (0.23.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in ./dev/lib/python3.11/site-packages (from jupyter-events>=0.11.0->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (3.3.0)\n",
      "Requirement already satisfied: rfc3339-validator in ./dev/lib/python3.11/site-packages (from jupyter-events>=0.11.0->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in ./dev/lib/python3.11/site-packages (from jupyter-events>=0.11.0->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (0.1.1)\n",
      "Requirement already satisfied: fqdn in ./dev/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (1.5.1)\n",
      "Requirement already satisfied: isoduration in ./dev/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in ./dev/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (3.0.0)\n",
      "Requirement already satisfied: uri-template in ./dev/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in ./dev/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in ./dev/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (1.17.1)\n",
      "Requirement already satisfied: pycparser in ./dev/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in ./dev/lib/python3.11/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in ./dev/lib/python3.11/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (2.9.0.20241206)\n",
      "Downloading jupyter_highlight_selected_word-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading jupyter_nbextensions_configurator-0.6.4-py2.py3-none-any.whl (466 kB)\n",
      "Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Using cached lxml-5.3.1-cp311-cp311-macosx_10_9_x86_64.whl (4.4 MB)\n",
      "Building wheels for collected packages: jupyter_contrib_nbextensions, jupyter_contrib_core\n",
      "  Building wheel for jupyter_contrib_nbextensions (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jupyter_contrib_nbextensions: filename=jupyter_contrib_nbextensions-0.7.0-py2.py3-none-any.whl size=23428843 sha256=67ef906b821ca6f6c5c7cc1654c789bc23afc4308f58c56abb0e4f06a24a43cf\n",
      "  Stored in directory: /Users/jhall/Library/Caches/pip/wheels/cd/25/fe/cb6f3e82f5b1921b0157ac9e32adb2e54806ec1befc446be21\n",
      "  Building wheel for jupyter_contrib_core (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jupyter_contrib_core: filename=jupyter_contrib_core-0.4.2-py2.py3-none-any.whl size=17535 sha256=796c1dd0c1a37659c7e3e78fd1859dc306fcb01eeada6b602188100d49baa8c5\n",
      "  Stored in directory: /Users/jhall/Library/Caches/pip/wheels/37/c3/18/be7a983c1120f15dc0c2d1cb9c33749871a93b034185e00ced\n",
      "Successfully built jupyter_contrib_nbextensions jupyter_contrib_core\n",
      "Installing collected packages: jupyter_highlight_selected_word, ipython_genutils, lxml, jupyter_contrib_core, jupyter_nbextensions_configurator, jupyter_contrib_nbextensions\n",
      "Successfully installed ipython_genutils-0.2.0 jupyter_contrib_core-0.4.2 jupyter_contrib_nbextensions-0.7.0 jupyter_highlight_selected_word-0.2.0 jupyter_nbextensions_configurator-0.6.4 lxml-5.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas openai tqdm dotenv openai-agents ipywidgets jupyter_contrib_nbextensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv('API_KEY'))\n",
    "tqdm.pandas()  # Enable progress_apply for pandas operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Preparation\n",
    "In this step, we read the input CSV files which contains the shot data. Then we are going to enrich the data by using `4o-mini` to analyze and provide feedback on each golfer's shot. We take this extra step to add semantic information for our vector store to use querying for results later on. The enriched files will be output into new CSV files in the `/processed` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [03:36<00:00,  2.77s/it]:00<?, ?it/s]\n",
      "Processing CSV files:   8%|▊         | 1/13 [03:36<43:14, 216.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to /Users/jhall/code/openai-cookbook/examples/agents_sdk/basics_of_agents_sdk/data/processed/Golf_Shot_Data_9.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [04:39<00:00,  2.11s/it]\n",
      "Processing CSV files:  15%|█▌        | 2/13 [08:15<46:25, 253.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to /Users/jhall/code/openai-cookbook/examples/agents_sdk/basics_of_agents_sdk/data/processed/Golf_Shot_Data_8.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [05:46<00:00,  3.06s/it]\n",
      "Processing CSV files:  23%|██▎       | 3/13 [14:01<49:16, 295.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to /Users/jhall/code/openai-cookbook/examples/agents_sdk/basics_of_agents_sdk/data/processed/Golf_Shot_Data_10.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [02:00<00:00,  2.28s/it]\n",
      "Processing CSV files:  31%|███       | 4/13 [16:02<33:59, 226.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to /Users/jhall/code/openai-cookbook/examples/agents_sdk/basics_of_agents_sdk/data/processed/Golf_Shot_Data_12.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [01:16<00:00,  1.95s/it]\n",
      "Processing CSV files:  38%|███▊      | 5/13 [17:18<22:59, 172.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to /Users/jhall/code/openai-cookbook/examples/agents_sdk/basics_of_agents_sdk/data/processed/Golf_Shot_Data_13.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [01:05<00:00,  1.93s/it]\n",
      "Processing CSV files:  46%|████▌     | 6/13 [18:23<15:52, 136.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to /Users/jhall/code/openai-cookbook/examples/agents_sdk/basics_of_agents_sdk/data/processed/Golf_Shot_Data_0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [04:10<00:00,  2.48s/it]\n",
      "Processing CSV files:  54%|█████▍    | 7/13 [22:34<17:21, 173.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to /Users/jhall/code/openai-cookbook/examples/agents_sdk/basics_of_agents_sdk/data/processed/Golf_Shot_Data_1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [01:59<00:00,  2.18s/it]\n",
      "Processing CSV files:  62%|██████▏   | 8/13 [24:34<13:02, 156.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to /Users/jhall/code/openai-cookbook/examples/agents_sdk/basics_of_agents_sdk/data/processed/Golf_Shot_Data_3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [03:12<00:00,  2.29s/it]\n",
      "Processing CSV files:  69%|██████▉   | 9/13 [27:47<11:10, 167.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to /Users/jhall/code/openai-cookbook/examples/agents_sdk/basics_of_agents_sdk/data/processed/Golf_Shot_Data_2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [02:45<00:00,  2.44s/it]\n",
      "Processing CSV files:  77%|███████▋  | 10/13 [30:32<08:21, 167.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to /Users/jhall/code/openai-cookbook/examples/agents_sdk/basics_of_agents_sdk/data/processed/Golf_Shot_Data_6.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [04:47<00:00,  2.18s/it]\n",
      "Processing CSV files:  85%|████████▍ | 11/13 [35:20<06:48, 204.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to /Users/jhall/code/openai-cookbook/examples/agents_sdk/basics_of_agents_sdk/data/processed/Golf_Shot_Data_7.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [02:25<00:00,  2.35s/it]\n",
      "Processing CSV files:  92%|█████████▏| 12/13 [37:46<03:06, 186.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to /Users/jhall/code/openai-cookbook/examples/agents_sdk/basics_of_agents_sdk/data/processed/Golf_Shot_Data_5.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [02:18<00:00,  2.06s/it]\n",
      "Processing CSV files: 100%|██████████| 13/13 [40:04<00:00, 184.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to /Users/jhall/code/openai-cookbook/examples/agents_sdk/basics_of_agents_sdk/data/processed/Golf_Shot_Data_4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_INSTRUCTIONS = \"\"\"\n",
    "You are a professional and very popular golf instructor with years of experience. You have a deep understanding of a variety of golf drills and exercises that can help golfers improve their game. You excel at synthesizing complex golf metrics from launch monitors and distilling them into comprehensible and actionable feedback and tips without being too technical. Convert it into lamens terms for high handicappers.\n",
    "\"\"\"\n",
    "\n",
    "def generate_feedback(row):\n",
    "    prompt = f\"\"\"\n",
    "    Review the following shot data and provide concise feedback:\n",
    "\n",
    "    Date: {row.get('Date', 'N/A')}\n",
    "    Club Type: {row.get('Club Type', 'N/A')}\n",
    "    Club Speed: {row.get('Club Speed', 'N/A')} mph\n",
    "    Attack Angle: {row.get('Attack Angle', 'N/A')} degrees\n",
    "    Club Path: {row.get('Club Path', 'N/A')} degrees\n",
    "    Club Face: {row.get('Club Face', 'N/A')} degrees\n",
    "    Face To Path: {row.get('Face To Path', 'N/A')} degrees\n",
    "    Ball Speed: {row.get('Ball Speed', 'N/A')} mph\n",
    "    Smash Factor: {row.get('Smash Factor', 'N/A')}\n",
    "    Launch Angle: {row.get('Launch Angle', 'N/A')} degrees\n",
    "    Launch Direction: {row.get('Launch Direction', 'N/A')} degrees\n",
    "    Backspin: {row.get('Backspin', 'N/A')} rpm\n",
    "    Sidespin: {row.get('Sidespin', 'N/A')} rpm\n",
    "    Spin Rate: {row.get('Spin Rate', 'N/A')} rpm\n",
    "    Spin Rate Type: {row.get('Spin Rate Type', 'N/A')}\n",
    "    Spin Axis: {row.get('Spin Axis', 'N/A')} degrees\n",
    "    Apex Height: {row.get('Apex Height', 'N/A')} yards\n",
    "    Carry Distance: {row.get('Carry Distance', 'N/A')} yards\n",
    "    Carry Deviation Angle: {row.get('Carry Deviation Angle', 'N/A')} degrees\n",
    "    Carry Deviation Distance: {row.get('Carry Deviation Distance', 'N/A')} yards\n",
    "    Total Distance: {row.get('Total Distance', 'N/A')} yards\n",
    "    Total Deviation Angle: {row.get('Total Deviation Angle', 'N/A')} degrees\n",
    "    Total Deviation Distance: {row.get('Total Deviation Distance', 'N/A')} yards\n",
    "    Note: {row.get('Note', 'N/A')}\n",
    "    Tag: {row.get('Tag', 'N/A')}\n",
    "    Air Density: {row.get('Air Density', 'N/A')} g/L\n",
    "    Temperature: {row.get('Temperature', 'N/A')} °F\n",
    "    Air Pressure: {row.get('Air Pressure', 'N/A')} kPa\n",
    "    Relative Humidity: {row.get('Relative Humidity', 'N/A')}%\n",
    "\n",
    "    Provide brief feedback and a short tag describing a drill that the golfer can do to improve their game such as \"step through drill\", \"swing path drill\", \"slow motion swing\", \"shoulder turn check\", \"half swing pause\", etc.\n",
    "    Format your response as JSON:\n",
    "    {{\n",
    "        \"feedback\": \"Your feedback here\",\n",
    "        \"tag\": \"Your tag here\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_INSTRUCTIONS},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        text={\n",
    "            \"format\": {\n",
    "                \"type\": \"json_object\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    result = response.output_text\n",
    "    return pd.Series(eval(result))\n",
    "\n",
    "def process_and_enrich_csv(filepath, output_filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    feedback_tags = df.progress_apply(generate_feedback, axis=1)\n",
    "    df['Note'] = feedback_tags['feedback']\n",
    "    df['Tag'] = feedback_tags['tag']\n",
    "    df.to_csv(output_filepath, index=False)\n",
    "    print(f\"Updated CSV saved to {output_filepath}\")\n",
    "\n",
    "data_folder = os.path.join(os.path.dirname(os.getcwd()), \"basics_of_agents_sdk/data\")\n",
    "raw_data_folder = os.path.join(data_folder, 'raw')\n",
    "enriched_data_folder = os.path.join(data_folder, 'processed')\n",
    "\n",
    "# Loop through each CSV file in the raw data folder with a progress bar\n",
    "for filename in tqdm(os.listdir(raw_data_folder), desc=\"Processing CSV files\"):\n",
    "    if filename.endswith('.csv'):\n",
    "        csv_path = os.path.join(raw_data_folder, filename)\n",
    "        output_filepath = os.path.join(enriched_data_folder, filename)\n",
    "        process_and_enrich_csv(csv_path, output_filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Uploading to File Search API (Vector Store)\n",
    "Now that we have our enriched data, we're going to chunk each CSV file by shot (i.e each row) and upload these files to our vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing CSV files: 100%|██████████| 26/26 [00:00<00:00, 629.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded batch 1/5: vsfb_8d785ab27d9b4846980ffbb472191b2f, Status: in_progress\n",
      "Uploaded batch 2/5: vsfb_936564cac61e4c3e9cdb34b14964aca2, Status: completed\n",
      "Uploaded batch 3/5: vsfb_59134cd12fc84d9495b318e91906e3a4, Status: in_progress\n",
      "Uploaded batch 4/5: vsfb_ee98a2921ffc41e3b7b9998d60191c3c, Status: in_progress\n",
      "Uploaded batch 5/5: vsfb_15ba2ef6ac39446fafe02a20cf177a5e, Status: in_progress\n"
     ]
    }
   ],
   "source": [
    "def upload_chunks_from_file(file_name, data_folder, purpose, max_retries=3, backoff_factor=2, use_cache=False):\n",
    "    filepath = os.path.join(data_folder, file_name)\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"File {file_name} does not exist in {data_folder}.\")\n",
    "        return {}\n",
    "    df = pd.read_csv(filepath)\n",
    "    chunk_file_ids = {}\n",
    "    cache_path = os.path.join(data_folder, f\"{os.path.splitext(file_name)[0]}_upload_cache.json\")\n",
    "    if use_cache and os.path.exists(cache_path):\n",
    "        with open(cache_path, 'r', encoding='utf-8') as cache_file:\n",
    "            upload_cache = json.load(cache_file)\n",
    "    else:\n",
    "        upload_cache = {}\n",
    "    for i, row in df.iterrows():\n",
    "        temp_chunk_filename = os.path.splitext(file_name)[0] + f\"_chunk_{i}.txt\"\n",
    "        if use_cache and temp_chunk_filename in upload_cache:\n",
    "            chunk_file_ids[temp_chunk_filename] = upload_cache[temp_chunk_filename]\n",
    "            # print(f\"Skipping chunk {i} of {file_name}; already uploaded.\")\n",
    "            continue\n",
    "        chunk_text = row.to_json()\n",
    "        temp_chunk_filepath = os.path.join(data_folder, temp_chunk_filename)\n",
    "        with open(temp_chunk_filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(chunk_text)\n",
    "        chunk_file_id = None\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                with open(temp_chunk_filepath, 'rb') as f:\n",
    "                    response = client.files.create(file=f, purpose=purpose)\n",
    "                chunk_file_id = response.id\n",
    "                # print(f\"Uploaded chunk {i} of {file_name} with id: {chunk_file_id}\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                sleep_time = backoff_factor * (2 ** attempt) + random.uniform(0, 0.1)\n",
    "                print(f\"Attempt {attempt+1} failed for chunk {i} of {file_name}: {e}\")\n",
    "                time.sleep(sleep_time)\n",
    "        if chunk_file_id:\n",
    "            chunk_file_ids[temp_chunk_filename] = chunk_file_id\n",
    "            if use_cache:\n",
    "                upload_cache[temp_chunk_filename] = chunk_file_id\n",
    "                with open(cache_path, 'w', encoding='utf-8') as cache_file:\n",
    "                    json.dump(upload_cache, cache_file)\n",
    "        else:\n",
    "            print(f\"Failed to upload chunk {i} of {file_name} after {max_retries} attempts.\")\n",
    "        os.remove(temp_chunk_filepath)\n",
    "    return chunk_file_ids\n",
    "\n",
    "def upload_all_ready_chunks(data_folder, purpose='user_data'):\n",
    "    all_chunk_ids = {}\n",
    "    for file_name in tqdm(os.listdir(data_folder), desc='Processing CSV files'):\n",
    "        if file_name.endswith('.csv'):\n",
    "            chunk_ids = upload_chunks_from_file(file_name, data_folder, purpose, use_cache=True)\n",
    "            if chunk_ids:\n",
    "                all_chunk_ids[file_name] = chunk_ids\n",
    "    # print('All uploaded chunk file IDs:')\n",
    "    # for original_file, chunks in all_chunk_ids.items():\n",
    "    #     # print(f\"{original_file}:\")\n",
    "    #     for chunk_filename, chunk_id in chunks.items():\n",
    "    #         print(f\"    {chunk_filename}: {chunk_id}\")\n",
    "    return all_chunk_ids\n",
    "\n",
    "def chunk_list(input_list, chunk_size):\n",
    "    \"\"\"Splits a list into smaller chunks.\"\"\"\n",
    "    return [input_list[i:i + chunk_size] for i in range(0, len(input_list), chunk_size)]\n",
    "\n",
    "\n",
    "def upload_to_vector_store(all_chunk_ids, vector_store_id, chunk_size=250):\n",
    "    all_file_ids = [chunk_id for file_chunks in all_chunk_ids.values() for chunk_id in file_chunks.values()]\n",
    "    file_id_batches = chunk_list(all_file_ids, chunk_size)\n",
    "    for idx, batch in enumerate(file_id_batches):\n",
    "        vector_store_batch = client.vector_stores.file_batches.create(\n",
    "            file_ids=batch,\n",
    "            vector_store_id=vector_store_id\n",
    "        )\n",
    "        print(f\"Uploaded batch {idx + 1}/{len(file_id_batches)}: {vector_store_batch.id}, Status: {vector_store_batch.status}\")\n",
    "\n",
    "\n",
    "SHOT_DATA_VECTOR_STORE_ID = os.getenv('SHOT_DATA_VECTOR_STORE_ID')\n",
    "data_folder = os.path.join(os.path.dirname(os.getcwd()), \"basics_of_agents_sdk/data\")\n",
    "enriched_data_folder = os.path.join(data_folder, 'processed')\n",
    "all_chunk_ids = upload_all_ready_chunks(enriched_data_folder)\n",
    "upload_to_vector_store(all_chunk_ids, SHOT_DATA_VECTOR_STORE_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our Vector Store in place, it's time to start building our Agents!\n",
    "\n",
    "## Agent Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from agents import Agent, Runner, ModelSettings, FileSearchTool, WebSearchTool, OpenAIResponsesModel, RunHooks\n",
    "from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX\n",
    "import openai\n",
    "import os\n",
    "import colorama\n",
    "from colorama import Fore, Style\n",
    "colorama.init(autoreset=True)\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "SHOT_DATA_VECTOR_STORE_ID = os.getenv('SHOT_DATA_VECTOR_STORE_ID')\n",
    "\n",
    "ORCHESTRATOR_INSTRUCTIONS = \"\"\"\n",
    "{RECOMMENDED_PROMPT_PREFIX}\n",
    "You are GolfNavigator, a knowledgeable golf assistant specializing in understanding user golf needs and routing them to the appropriate service. Your primary responsibilities are to:\n",
    "\t1.\tEngage with the User:\n",
    "\t    •\tInitiate friendly and informed conversation using accurate golf terminology.\n",
    "\t2.\tUnderstand Intent:\n",
    "\t    •\tAnalyze the user’s input to determine if they require detailed analysis of shot data and a tailored practice plan, or if they are looking for course recommendations.\n",
    "\t    •\tRecognize keywords and phrases related to practice sessions (e.g., ‘practice’, ‘drills’, ‘shot data analysis’) or tee times (e.g., ‘play’, ‘course’, ‘round’, ‘weather’).\n",
    "\t3.\tRoute the Request:\n",
    "\t    •\tIf the user’s inquiry involves reviewing shot data, performance analysis, or developing a practice regimen, forward the request to the transfer_to_practice_planner agent.\n",
    "\t    •\tIf the user is interested in course recommendations based on their skills, availability, weather conditions, and a predicted score, forward the inquiry to the transfer_to_tee_time_finder agent, ensuring up to 3 course options are provided.\n",
    "\t4.\tMaintain Golf Expertise:\n",
    "\t    •\tUse golf-specific language naturally and confidently.\n",
    "\t    •\tProvide contextually relevant insights about golf techniques, course conditions, and performance metrics when engaging with the user.\n",
    "\t5.\tAdditional Considerations:\n",
    "\t    •\tConfirm user details (like availability or skill level) when needed to ensure the proper agent receives all necessary information.\n",
    "\t    •\tIf uncertain about user intent, ask follow-up questions to clarify before making a routing decision.\n",
    "\n",
    "By following these guidelines, you ensure that the user is efficiently directed to the correct specialist while maintaining a high level of golf expertise.\n",
    "\"\"\"\n",
    "\n",
    "PRACTICE_PLANNER_INSTRUCTIONS = \"\"\"\n",
    "You are PracticePlanner Pro, a seasoned industry veteran and dedicated golf instructor with decades of experience, specializing in creating custom practice plans for players of all handicap levels. Your task is to analyze the user’s shot data and extract relevant patterns and trends to create a structured, single-day driving range session plan. Your practice plan should include a section-by-section breakdown of drills and exercises, with clear explanations of what to work on and the benefits of each drill.\n",
    "\n",
    "Your responsibilities include:\n",
    "\t1.\tData Analysis:\n",
    "\t    •\tThoroughly review the user’s shot data to identify recurring issues, strengths, and areas for improvement.\n",
    "\t    •\tCorrelate specific shot types, distances, or errors to tailor the practice drills accordingly.\n",
    "\t2.\tPlan Structure:\n",
    "\t    •\tDevelop a comprehensive, single-day driving range session plan that is detailed and easy to follow.\n",
    "\t    •\tDivide the session into clear segments (e.g., warm-up, skill-specific drills, focused practice on weaknesses, cool-down, etc.).\n",
    "\t3.\tDrill Breakdown:\n",
    "\t    •\tFor each section, provide:\n",
    "\t        •\tDrill Name & Description: What the drill involves.\n",
    "\t        •\tObjective: What skill or aspect of the game is being targeted.\n",
    "\t        •\tBenefits: How the drill will improve the golfer’s performance (e.g., better shot consistency, improved swing mechanics, increased accuracy).\n",
    "\t    •\tEnsure that the drills are practical and can be executed during a typical driving range session.\n",
    "\t4.\tExpert Guidance:\n",
    "\t    •\tUse language that reflects your expertise as a veteran instructor.\n",
    "\t    •\tInclude insights and tips that demonstrate your deep understanding of golf techniques and performance optimization.\n",
    "\t    •\tConsider the varied needs of players across different handicap levels, ensuring drills can be adjusted for beginners and advanced players alike.\n",
    "\t5.\tUser Engagement:\n",
    "\t    •\tWhen necessary, ask clarifying questions about the user’s data to ensure that your recommendations are as accurate and personalized as possible.\n",
    "\t    •\tOffer suggestions for follow-up sessions or further analysis if the shot data indicates persistent issues.\n",
    "\n",
    "By following these instructions, you will provide the golfer with a detailed, actionable practice session plan that leverages their shot data to target specific improvements and ultimately enhance their game.\n",
    "\"\"\"\n",
    "\n",
    "TEE_TIME_FINDER_INSTRUCTIONS = \"\"\"\n",
    "You are TeeTimeFinder, a specialized assistant dedicated to delivering personalized golf course recommendations and predictive scoring. Your responsibilities are as follows:\n",
    "\n",
    "1. Course Recommendations:\n",
    "\t•\tSelection: Identify and select up to 3 golf courses near the user’s location.\n",
    "\t•\tData Retrieval: \n",
    "\t    •\tUse the web search tool to obtain current, accurate details for each course, including:\n",
    "\t        •\tCourse name\n",
    "\t        •\tLocation\n",
    "\t        •\tSlope rating\n",
    "\t        •\tCourse rating\n",
    "\t        •\tAccuracy: Ensure all course details are up-to-date to provide the best recommendations.\n",
    "        •\tYou can use the FileSearch tool to get the course details from the user's shot data\n",
    "\n",
    "2. Score Prediction:\n",
    "\t•\tCalculation: Predict the user’s score by analyzing:\n",
    "\t•\tTheir personal shot data that you have access to in the FileSearch\n",
    "\t•\tExpected weather conditions on the specified play date\n",
    "\t•\tCourse-specific metrics (slope and rating)\n",
    "\t•\tExplanation: Provide a brief explanation of how factors (weather, shot data, slope, and course rating) interact. For example, note that “High winds combined with a steep slope might result in a slightly higher predicted score.”\n",
    "\t•\tOutput: Include the predicted score alongside each recommended course.\n",
    "\n",
    "3. Club Distance Recommendations:\n",
    "\t•\tData Presentation: Provide a Markdown table listing the recommended distances for each club.\n",
    "\t•\tContent Details:\n",
    "\t    •\tFor clubs where existing shot data is available, show the known distance (e.g., “PW – 120 yards”).\n",
    "\t    •\tFor clubs without shot data, offer a reasoned prediction based on your expertise.\n",
    "\t•\tTable Requirements: Only include clubs for which you have verifiable data or can credibly predict a distance.\n",
    "\n",
    "4. Data Collection & Clarification:\n",
    "\t•\tClarification: Ask the user for any missing required information to ensure accurate recommendations and predictions.\n",
    "\n",
    "5. Integration of Data:\n",
    "\t•\tMerging Insights: Combine the user’s shot data, weather forecasts, and course metrics (slope and rating) to refine both your course recommendations and score predictions.\n",
    "\t•\tPresentation: Organize all details clearly and logically.\n",
    "\n",
    "6. Communication & Presentation:\n",
    "\t•\tCourse Details: Present the recommended golf courses along with key details (name, location, slope, course rating) in a clear, concise manner.\n",
    "\t•\tScore Prediction: Include the predicted score for each course, with a short rationale explaining the prediction.\n",
    "\t•\tClub Distance Table: Display the club distance recommendations using a well-formatted Markdown table.\n",
    "\n",
    "7. Expert Guidance:\n",
    "\t•\tKnowledge Base: Utilize your expertise in golf, player performance, and environmental factors to deliver trustworthy and tailored advice.\n",
    "\t•\tProfessional Tone: Maintain a clear, professional tone using accurate golf terminology to build confidence in your recommendations.\n",
    "\n",
    "By following these refined instructions, you will deliver a comprehensive, personalized experience that includes current course recommendations, detailed score predictions, and a practical club distance table—all while ensuring all necessary user data is collected before proceeding\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "practice_planner_agent = Agent(\n",
    "    name=\"Practice Planner\",\n",
    "    instructions=PRACTICE_PLANNER_INSTRUCTIONS,\n",
    "    handoffs=[],\n",
    "    tools=[\n",
    "        FileSearchTool(\n",
    "            vector_store_ids=[SHOT_DATA_VECTOR_STORE_ID],\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "tee_time_finder_agent = Agent(\n",
    "    name=\"Tee Time Finder\",\n",
    "    instructions=TEE_TIME_FINDER_INSTRUCTIONS,\n",
    "    model=OpenAIResponsesModel(model=\"gpt-4o\", openai_client=openai.AsyncOpenAI()),\n",
    "    tools=[\n",
    "        WebSearchTool(),\n",
    "        FileSearchTool(\n",
    "            vector_store_ids=[SHOT_DATA_VECTOR_STORE_ID],\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "main_agent = Agent(\n",
    "    name=\"Orchestrator\",\n",
    "    instructions=ORCHESTRATOR_INSTRUCTIONS,\n",
    "    model=OpenAIResponsesModel(model=\"gpt-4o-mini\", openai_client=openai.AsyncOpenAI()),\n",
    "    handoffs=[practice_planner_agent, tee_time_finder_agent]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe6d92718fd4b9a992c8bcff8cd6d67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', continuous_update=False, description='User:', placeholder='Type your message...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0846b12461ac44f0a065e32d384089e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()  # Allows nested event loops in Jupyter\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from colorama import Fore, Style\n",
    "# Store conversation history\n",
    "conversation = []\n",
    "\n",
    "# Create a text widget for user input\n",
    "user_input_box = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type your message...',\n",
    "    description='User:',\n",
    "    disabled=False,\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "# Create an output widget to display conversation\n",
    "output_area = widgets.Output()\n",
    "\n",
    "async def handle_user_input_async(user_text):\n",
    "    global conversation\n",
    "    \n",
    "    # Check for exit\n",
    "    if user_text.lower() in ('exit', 'quit'):\n",
    "        with output_area:\n",
    "            output_area.append_stdout(\n",
    "                Fore.RED + \"Exiting the program. Goodbye!\\n\" + Style.RESET_ALL\n",
    "            )\n",
    "        # Optionally disable the input box if we want to stop further input\n",
    "        user_input_box.disabled = True\n",
    "        return\n",
    "\n",
    "    # Add the user's message to the conversation history\n",
    "    conversation.append({\"role\": \"user\", \"content\": user_text})\n",
    "    \n",
    "    output = await Runner.run(main_agent, conversation)\n",
    "\n",
    "    # Display the agent's response\n",
    "    with output_area:\n",
    "        output_area.append_stdout(\n",
    "            Fore.GREEN + \"Agent: \" + Style.RESET_ALL + output.final_output + \"\\n\"\n",
    "        )\n",
    "    \n",
    "    # Update conversation history to include the agent's output\n",
    "    conversation[:] = output.to_input_list()\n",
    "\n",
    "def on_text_submit(change):\n",
    "    # Only process non-empty submissions.\n",
    "    if change['name'] == 'value' and change['type'] == 'change' and change['new'].strip():\n",
    "        user_text = change['new']\n",
    "        # Clear the input box immediately to avoid duplicate events.\n",
    "        user_input_box.value = ''\n",
    "        asyncio.create_task(handle_user_input_async(user_text))\n",
    "\n",
    "# Observe 'value' changes in the text widget\n",
    "user_input_box.observe(on_text_submit, names='value')\n",
    "\n",
    "display(user_input_box, output_area)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basics_agent_sdk",
   "language": "python",
   "name": "basics_agent_sdk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
